{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb277049-b700-4107-8ee6-089a11ef000f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Over parameterized network Non decreasing lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fe1ba3-4d2f-4131-a53e-40ca1bd0c78f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected weight:[16]\n",
      "train data size:2000\n",
      "test data size:256\n",
      "Time:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b1323fb1204a4eaafbdf93413dbdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(5.6682, dtype=torch.float64)\n",
      "hess: tensor(47.9316)\n",
      "\taccuracy:12.109375\n",
      "\tloss: 2.321805\n",
      "grad: tensor(4.1539, dtype=torch.float64)\n",
      "hess: tensor(30.3194)\n",
      "grad: tensor(2.7233, dtype=torch.float64)\n",
      "hess: tensor(21.9250)\n",
      "grad: tensor(3.9320, dtype=torch.float64)\n",
      "hess: tensor(33.5948)\n",
      "grad: tensor(2.4536, dtype=torch.float64)\n",
      "hess: tensor(18.0610)\n",
      "grad: tensor(2.9556, dtype=torch.float64)\n",
      "hess: tensor(24.9243)\n",
      "grad: tensor(4.2075, dtype=torch.float64)\n",
      "hess: tensor(42.0566)\n",
      "grad: tensor(3.3555, dtype=torch.float64)\n",
      "hess: tensor(25.6617)\n",
      "grad: tensor(3.8782, dtype=torch.float64)\n",
      "hess: tensor(34.7406)\n",
      "grad: tensor(2.4636, dtype=torch.float64)\n",
      "hess: tensor(21.2966)\n",
      "grad: tensor(4.7116, dtype=torch.float64)\n",
      "hess: tensor(33.4358)\n",
      "grad: tensor(4.7587, dtype=torch.float64)\n",
      "hess: tensor(42.1473)\n",
      "grad: tensor(3.0337, dtype=torch.float64)\n",
      "hess: tensor(28.4914)\n",
      "grad: tensor(4.1236, dtype=torch.float64)\n",
      "hess: tensor(31.7487)\n",
      "grad: tensor(3.6928, dtype=torch.float64)\n",
      "hess: tensor(26.0059)\n",
      "grad: tensor(3.6983, dtype=torch.float64)\n",
      "hess: tensor(47.2904)\n",
      "grad: tensor(3.9954, dtype=torch.float64)\n",
      "hess: tensor(46.8821)\n",
      "grad: tensor(5.5052, dtype=torch.float64)\n",
      "hess: tensor(43.5562)\n",
      "grad: tensor(3.8673, dtype=torch.float64)\n",
      "hess: tensor(33.2236)\n",
      "grad: tensor(5.6367, dtype=torch.float64)\n",
      "hess: tensor(44.7732)\n",
      "grad: tensor(4.2363, dtype=torch.float64)\n",
      "hess: tensor(35.0195)\n",
      "grad: tensor(3.6978, dtype=torch.float64)\n",
      "hess: tensor(27.1208)\n",
      "grad: tensor(5.9674, dtype=torch.float64)\n",
      "hess: tensor(45.2548)\n",
      "grad: tensor(2.6201, dtype=torch.float64)\n",
      "hess: tensor(30.4258)\n",
      "grad: tensor(5.7956, dtype=torch.float64)\n",
      "hess: tensor(47.0203)\n",
      "grad: tensor(6.1075, dtype=torch.float64)\n",
      "hess: tensor(54.3928)\n",
      "grad: tensor(3.7752, dtype=torch.float64)\n",
      "hess: tensor(21.6191)\n",
      "grad: tensor(5.9132, dtype=torch.float64)\n",
      "hess: tensor(47.2709)\n",
      "grad: tensor(4.9652, dtype=torch.float64)\n",
      "hess: tensor(43.7004)\n",
      "grad: tensor(3.5367, dtype=torch.float64)\n",
      "hess: tensor(29.8718)\n",
      "grad: tensor(5.5984, dtype=torch.float64)\n",
      "hess: tensor(48.3810)\n",
      "grad: tensor(4.6516, dtype=torch.float64)\n",
      "hess: tensor(29.6797)\n",
      "grad: tensor(4.0578, dtype=torch.float64)\n",
      "hess: tensor(50.5115)\n",
      "grad: tensor(3.9866, dtype=torch.float64)\n",
      "hess: tensor(29.1807)\n",
      "grad: tensor(3.6176, dtype=torch.float64)\n",
      "hess: tensor(32.4372)\n",
      "grad: tensor(4.1416, dtype=torch.float64)\n",
      "hess: tensor(41.0872)\n",
      "grad: tensor(4.2995, dtype=torch.float64)\n",
      "hess: tensor(30.5666)\n",
      "grad: tensor(4.7613, dtype=torch.float64)\n",
      "hess: tensor(39.8848)\n",
      "grad: tensor(3.7959, dtype=torch.float64)\n",
      "hess: tensor(37.4458)\n",
      "grad: tensor(4.3778, dtype=torch.float64)\n",
      "hess: tensor(28.0340)\n",
      "grad: tensor(3.4235, dtype=torch.float64)\n",
      "hess: tensor(22.5528)\n",
      "grad: tensor(4.3625, dtype=torch.float64)\n",
      "hess: tensor(41.4403)\n",
      "grad: tensor(3.9923, dtype=torch.float64)\n",
      "hess: tensor(28.0433)\n",
      "grad: tensor(5.7682, dtype=torch.float64)\n",
      "hess: tensor(36.4532)\n",
      "grad: tensor(5.6435, dtype=torch.float64)\n",
      "hess: tensor(46.1920)\n",
      "grad: tensor(3.7192, dtype=torch.float64)\n",
      "hess: tensor(28.1650)\n",
      "grad: tensor(3.0880, dtype=torch.float64)\n",
      "hess: tensor(27.0929)\n",
      "grad: tensor(5.6746, dtype=torch.float64)\n",
      "hess: tensor(39.3471)\n",
      "grad: tensor(5.7669, dtype=torch.float64)\n",
      "hess: tensor(35.2610)\n",
      "grad: tensor(5.1067, dtype=torch.float64)\n",
      "hess: tensor(42.6986)\n",
      "grad: tensor(3.5993, dtype=torch.float64)\n",
      "hess: tensor(29.9484)\n",
      "\taccuracy:57.421875\n",
      "\tloss: 1.642464\n",
      "grad: tensor(7.2962, dtype=torch.float64)\n",
      "hess: tensor(51.0617)\n",
      "grad: tensor(5.2026, dtype=torch.float64)\n",
      "hess: tensor(39.4715)\n",
      "grad: tensor(5.3820, dtype=torch.float64)\n",
      "hess: tensor(40.9131)\n",
      "grad: tensor(3.3228, dtype=torch.float64)\n",
      "hess: tensor(25.8173)\n",
      "grad: tensor(4.4211, dtype=torch.float64)\n",
      "hess: tensor(25.4786)\n",
      "grad: tensor(5.5400, dtype=torch.float64)\n",
      "hess: tensor(41.1699)\n",
      "grad: tensor(5.8454, dtype=torch.float64)\n",
      "hess: tensor(40.4895)\n",
      "grad: tensor(4.7580, dtype=torch.float64)\n",
      "hess: tensor(29.9480)\n",
      "grad: tensor(4.8495, dtype=torch.float64)\n",
      "hess: tensor(47.6132)\n",
      "grad: tensor(5.7112, dtype=torch.float64)\n",
      "hess: tensor(44.5581)\n",
      "grad: tensor(5.1437, dtype=torch.float64)\n",
      "hess: tensor(32.2402)\n",
      "grad: tensor(11.5587, dtype=torch.float64)\n",
      "hess: tensor(81.0981)\n",
      "grad: tensor(6.4253, dtype=torch.float64)\n",
      "hess: tensor(56.4505)\n",
      "grad: tensor(4.6532, dtype=torch.float64)\n",
      "hess: tensor(32.0997)\n",
      "grad: tensor(4.1813, dtype=torch.float64)\n",
      "hess: tensor(33.4590)\n",
      "grad: tensor(5.3645, dtype=torch.float64)\n",
      "hess: tensor(45.9752)\n",
      "grad: tensor(5.8656, dtype=torch.float64)\n",
      "hess: tensor(39.1938)\n",
      "grad: tensor(7.9586, dtype=torch.float64)\n",
      "hess: tensor(50.4651)\n",
      "grad: tensor(5.4759, dtype=torch.float64)\n",
      "hess: tensor(33.6472)\n",
      "grad: tensor(5.7567, dtype=torch.float64)\n",
      "hess: tensor(43.5434)\n",
      "grad: tensor(4.3111, dtype=torch.float64)\n",
      "hess: tensor(23.8300)\n",
      "grad: tensor(5.1124, dtype=torch.float64)\n",
      "hess: tensor(43.2276)\n",
      "grad: tensor(4.2796, dtype=torch.float64)\n",
      "hess: tensor(29.8557)\n",
      "grad: tensor(4.1924, dtype=torch.float64)\n",
      "hess: tensor(26.1190)\n",
      "grad: tensor(3.3502, dtype=torch.float64)\n",
      "hess: tensor(22.3834)\n",
      "grad: tensor(6.0002, dtype=torch.float64)\n",
      "hess: tensor(35.7367)\n",
      "grad: tensor(7.6499, dtype=torch.float64)\n",
      "hess: tensor(61.6614)\n",
      "grad: tensor(9.5730, dtype=torch.float64)\n",
      "hess: tensor(69.2333)\n",
      "grad: tensor(3.4791, dtype=torch.float64)\n",
      "hess: tensor(25.1548)\n",
      "grad: tensor(4.1780, dtype=torch.float64)\n",
      "hess: tensor(27.9223)\n",
      "grad: tensor(5.0762, dtype=torch.float64)\n",
      "hess: tensor(39.3701)\n",
      "grad: tensor(3.8495, dtype=torch.float64)\n",
      "hess: tensor(20.1855)\n",
      "grad: tensor(6.4508, dtype=torch.float64)\n",
      "hess: tensor(38.3338)\n",
      "grad: tensor(5.8434, dtype=torch.float64)\n",
      "hess: tensor(45.6343)\n",
      "grad: tensor(9.3328, dtype=torch.float64)\n",
      "hess: tensor(66.4514)\n",
      "grad: tensor(4.8309, dtype=torch.float64)\n",
      "hess: tensor(33.3329)\n",
      "grad: tensor(4.9529, dtype=torch.float64)\n",
      "hess: tensor(43.4452)\n",
      "grad: tensor(6.1112, dtype=torch.float64)\n",
      "hess: tensor(40.6204)\n",
      "grad: tensor(5.4384, dtype=torch.float64)\n",
      "hess: tensor(35.1045)\n",
      "grad: tensor(3.4108, dtype=torch.float64)\n",
      "hess: tensor(29.8041)\n",
      "grad: tensor(1.3263, dtype=torch.float64)\n",
      "hess: tensor(16.3816)\n",
      "grad: tensor(11.3332, dtype=torch.float64)\n",
      "hess: tensor(92.7209)\n",
      "grad: tensor(1.8101, dtype=torch.float64)\n",
      "hess: tensor(24.8069)\n",
      "grad: tensor(3.9804, dtype=torch.float64)\n",
      "hess: tensor(29.5624)\n",
      "grad: tensor(7.9378, dtype=torch.float64)\n",
      "hess: tensor(42.6487)\n",
      "grad: tensor(5.5532, dtype=torch.float64)\n",
      "hess: tensor(41.1267)\n",
      "grad: tensor(7.4112, dtype=torch.float64)\n",
      "hess: tensor(50.5381)\n",
      "grad: tensor(7.0699, dtype=torch.float64)\n",
      "hess: tensor(47.4156)\n",
      "grad: tensor(3.8189, dtype=torch.float64)\n",
      "hess: tensor(25.1723)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6a15be1d37418f9e09c7ea1ff8373a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.4987, dtype=torch.float64)\n",
      "hess: tensor(26.0852)\n",
      "\taccuracy:77.734375\n",
      "\tloss: 0.084191\n",
      "grad: tensor(2.6057, dtype=torch.float64)\n",
      "hess: tensor(16.0827)\n",
      "grad: tensor(3.3794, dtype=torch.float64)\n",
      "hess: tensor(21.6846)\n",
      "grad: tensor(4.4570, dtype=torch.float64)\n",
      "hess: tensor(48.0313)\n",
      "grad: tensor(8.6845, dtype=torch.float64)\n",
      "hess: tensor(62.8313)\n",
      "grad: tensor(9.1012, dtype=torch.float64)\n",
      "hess: tensor(56.6166)\n",
      "grad: tensor(5.2375, dtype=torch.float64)\n",
      "hess: tensor(33.3023)\n",
      "grad: tensor(6.4423, dtype=torch.float64)\n",
      "hess: tensor(31.8750)\n",
      "grad: tensor(5.5797, dtype=torch.float64)\n",
      "hess: tensor(52.2950)\n",
      "grad: tensor(4.9951, dtype=torch.float64)\n",
      "hess: tensor(34.4495)\n",
      "grad: tensor(1.3686, dtype=torch.float64)\n",
      "hess: tensor(18.7939)\n",
      "grad: tensor(13.1814, dtype=torch.float64)\n",
      "hess: tensor(72.9718)\n",
      "grad: tensor(2.4902, dtype=torch.float64)\n",
      "hess: tensor(36.4559)\n",
      "grad: tensor(3.9532, dtype=torch.float64)\n",
      "hess: tensor(25.6626)\n",
      "grad: tensor(5.5795, dtype=torch.float64)\n",
      "hess: tensor(47.0928)\n",
      "grad: tensor(4.7986, dtype=torch.float64)\n",
      "hess: tensor(44.6733)\n",
      "grad: tensor(4.5630, dtype=torch.float64)\n",
      "hess: tensor(46.6196)\n",
      "grad: tensor(4.6396, dtype=torch.float64)\n",
      "hess: tensor(34.7749)\n",
      "grad: tensor(1.7146, dtype=torch.float64)\n",
      "hess: tensor(15.3767)\n",
      "grad: tensor(7.3731, dtype=torch.float64)\n",
      "hess: tensor(49.4347)\n",
      "grad: tensor(1.9974, dtype=torch.float64)\n",
      "hess: tensor(13.2786)\n",
      "grad: tensor(1.4208, dtype=torch.float64)\n",
      "hess: tensor(17.5230)\n",
      "grad: tensor(1.7172, dtype=torch.float64)\n",
      "hess: tensor(23.8511)\n",
      "grad: tensor(4.8716, dtype=torch.float64)\n",
      "hess: tensor(33.9877)\n",
      "grad: tensor(8.6225, dtype=torch.float64)\n",
      "hess: tensor(59.5232)\n",
      "grad: tensor(2.8703, dtype=torch.float64)\n",
      "hess: tensor(22.5912)\n",
      "\taccuracy:71.875\n",
      "\tloss: 0.364798\n",
      "grad: tensor(2.6575, dtype=torch.float64)\n",
      "hess: tensor(26.1925)\n",
      "grad: tensor(0.9186, dtype=torch.float64)\n",
      "hess: tensor(16.1324)\n",
      "grad: tensor(2.1820, dtype=torch.float64)\n",
      "hess: tensor(24.0091)\n",
      "grad: tensor(2.2137, dtype=torch.float64)\n",
      "hess: tensor(24.4562)\n",
      "grad: tensor(5.0595, dtype=torch.float64)\n",
      "hess: tensor(56.2925)\n",
      "grad: tensor(17.7635, dtype=torch.float64)\n",
      "hess: tensor(158.7949)\n",
      "grad: tensor(2.4000, dtype=torch.float64)\n",
      "hess: tensor(28.6449)\n",
      "grad: tensor(3.6313, dtype=torch.float64)\n",
      "hess: tensor(54.1068)\n",
      "grad: tensor(4.1987, dtype=torch.float64)\n",
      "hess: tensor(54.6820)\n",
      "grad: tensor(6.4726, dtype=torch.float64)\n",
      "hess: tensor(50.7970)\n",
      "grad: tensor(4.8938, dtype=torch.float64)\n",
      "hess: tensor(43.7513)\n",
      "grad: tensor(3.2453, dtype=torch.float64)\n",
      "hess: tensor(27.7593)\n",
      "grad: tensor(8.4926, dtype=torch.float64)\n",
      "hess: tensor(43.2973)\n",
      "grad: tensor(14.1624, dtype=torch.float64)\n",
      "hess: tensor(124.9130)\n",
      "grad: tensor(4.1392, dtype=torch.float64)\n",
      "hess: tensor(30.9275)\n",
      "grad: tensor(2.1634, dtype=torch.float64)\n",
      "hess: tensor(16.9478)\n",
      "grad: tensor(5.6470, dtype=torch.float64)\n",
      "hess: tensor(54.7594)\n",
      "grad: tensor(5.2726, dtype=torch.float64)\n",
      "hess: tensor(37.6915)\n",
      "grad: tensor(5.1143, dtype=torch.float64)\n",
      "hess: tensor(45.2860)\n",
      "grad: tensor(0.4426, dtype=torch.float64)\n",
      "hess: tensor(7.1146)\n",
      "grad: tensor(4.9255, dtype=torch.float64)\n",
      "hess: tensor(79.0393)\n",
      "grad: tensor(1.4300, dtype=torch.float64)\n",
      "hess: tensor(19.6303)\n",
      "grad: tensor(6.8043, dtype=torch.float64)\n",
      "hess: tensor(49.4557)\n",
      "grad: tensor(8.2772, dtype=torch.float64)\n",
      "hess: tensor(75.2485)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce56836744014704a7e5ef42f05a594c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.2192, dtype=torch.float64)\n",
      "hess: tensor(5.6381)\n",
      "\taccuracy:85.546875\n",
      "\tloss: 0.009083\n",
      "grad: tensor(1.4402, dtype=torch.float64)\n",
      "hess: tensor(12.6312)\n",
      "grad: tensor(1.7925, dtype=torch.float64)\n",
      "hess: tensor(17.0339)\n",
      "grad: tensor(2.7438, dtype=torch.float64)\n",
      "hess: tensor(46.9670)\n",
      "grad: tensor(10.8548, dtype=torch.float64)\n",
      "hess: tensor(97.8794)\n",
      "grad: tensor(14.5248, dtype=torch.float64)\n",
      "hess: tensor(86.8952)\n",
      "grad: tensor(4.8465, dtype=torch.float64)\n",
      "hess: tensor(39.4935)\n",
      "grad: tensor(8.3700, dtype=torch.float64)\n",
      "hess: tensor(43.4366)\n",
      "grad: tensor(2.0685, dtype=torch.float64)\n",
      "hess: tensor(30.4789)\n",
      "grad: tensor(5.0276, dtype=torch.float64)\n",
      "hess: tensor(44.3745)\n",
      "grad: tensor(0.1841, dtype=torch.float64)\n",
      "hess: tensor(3.7885)\n",
      "grad: tensor(17.5540, dtype=torch.float64)\n",
      "hess: tensor(104.7053)\n",
      "grad: tensor(0.5724, dtype=torch.float64)\n",
      "hess: tensor(12.4992)\n",
      "grad: tensor(3.5825, dtype=torch.float64)\n",
      "hess: tensor(32.2651)\n",
      "grad: tensor(1.7619, dtype=torch.float64)\n",
      "hess: tensor(24.4238)\n",
      "grad: tensor(1.2325, dtype=torch.float64)\n",
      "hess: tensor(19.5778)\n",
      "grad: tensor(1.3900, dtype=torch.float64)\n",
      "hess: tensor(23.0160)\n",
      "grad: tensor(5.2755, dtype=torch.float64)\n",
      "hess: tensor(43.6020)\n",
      "grad: tensor(0.4316, dtype=torch.float64)\n",
      "hess: tensor(5.6064)\n",
      "grad: tensor(7.3974, dtype=torch.float64)\n",
      "hess: tensor(64.4115)\n",
      "grad: tensor(1.0700, dtype=torch.float64)\n",
      "hess: tensor(9.0878)\n",
      "grad: tensor(0.4863, dtype=torch.float64)\n",
      "hess: tensor(8.4077)\n",
      "grad: tensor(0.3785, dtype=torch.float64)\n",
      "hess: tensor(7.7608)\n",
      "grad: tensor(5.5790, dtype=torch.float64)\n",
      "hess: tensor(42.0074)\n",
      "grad: tensor(8.3516, dtype=torch.float64)\n",
      "hess: tensor(74.0702)\n",
      "grad: tensor(1.3392, dtype=torch.float64)\n",
      "hess: tensor(15.3273)\n",
      "\taccuracy:79.296875\n",
      "\tloss: 0.114749\n",
      "grad: tensor(0.8004, dtype=torch.float64)\n",
      "hess: tensor(11.1273)\n",
      "grad: tensor(0.4047, dtype=torch.float64)\n",
      "hess: tensor(9.1813)\n",
      "grad: tensor(0.5625, dtype=torch.float64)\n",
      "hess: tensor(8.6131)\n",
      "grad: tensor(1.5788, dtype=torch.float64)\n",
      "hess: tensor(21.5203)\n",
      "grad: tensor(3.6473, dtype=torch.float64)\n",
      "hess: tensor(52.8877)\n",
      "grad: tensor(14.5192, dtype=torch.float64)\n",
      "hess: tensor(145.1471)\n",
      "grad: tensor(1.5171, dtype=torch.float64)\n",
      "hess: tensor(24.5717)\n",
      "grad: tensor(2.1104, dtype=torch.float64)\n",
      "hess: tensor(43.0852)\n",
      "grad: tensor(2.3817, dtype=torch.float64)\n",
      "hess: tensor(42.0879)\n",
      "grad: tensor(5.5426, dtype=torch.float64)\n",
      "hess: tensor(58.3550)\n",
      "grad: tensor(4.2819, dtype=torch.float64)\n",
      "hess: tensor(45.2674)\n",
      "grad: tensor(2.8818, dtype=torch.float64)\n",
      "hess: tensor(31.9530)\n",
      "grad: tensor(9.2753, dtype=torch.float64)\n",
      "hess: tensor(48.3286)\n",
      "grad: tensor(12.9375, dtype=torch.float64)\n",
      "hess: tensor(132.1763)\n",
      "grad: tensor(3.9413, dtype=torch.float64)\n",
      "hess: tensor(37.1805)\n",
      "grad: tensor(1.1675, dtype=torch.float64)\n",
      "hess: tensor(10.7616)\n",
      "grad: tensor(5.0832, dtype=torch.float64)\n",
      "hess: tensor(59.3390)\n",
      "grad: tensor(4.7046, dtype=torch.float64)\n",
      "hess: tensor(41.7615)\n",
      "grad: tensor(3.3464, dtype=torch.float64)\n",
      "hess: tensor(39.5234)\n",
      "grad: tensor(0.1837, dtype=torch.float64)\n",
      "hess: tensor(3.4471)\n",
      "grad: tensor(1.8279, dtype=torch.float64)\n",
      "hess: tensor(43.0251)\n",
      "grad: tensor(0.6776, dtype=torch.float64)\n",
      "hess: tensor(11.6447)\n",
      "grad: tensor(6.7197, dtype=torch.float64)\n",
      "hess: tensor(55.2961)\n",
      "grad: tensor(6.8617, dtype=torch.float64)\n",
      "hess: tensor(78.8882)\n",
      "grad: tensor(0.9439, dtype=torch.float64)\n",
      "hess: tensor(13.1451)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb8ade24a784e94ac263202301403b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0477, dtype=torch.float64)\n",
      "hess: tensor(1.3873)\n",
      "\taccuracy:88.671875\n",
      "\tloss: 0.001780\n",
      "grad: tensor(0.9067, dtype=torch.float64)\n",
      "hess: tensor(16.6503)\n",
      "grad: tensor(2.9936, dtype=torch.float64)\n",
      "hess: tensor(56.7542)\n",
      "grad: tensor(12.9979, dtype=torch.float64)\n",
      "hess: tensor(52.9321)\n",
      "grad: tensor(4.0614, dtype=torch.float64)\n",
      "hess: tensor(40.0575)\n",
      "grad: tensor(0.9960, dtype=torch.float64)\n",
      "hess: tensor(20.8969)\n",
      "grad: tensor(6.1704, dtype=torch.float64)\n",
      "hess: tensor(56.3833)\n",
      "grad: tensor(0.9177, dtype=torch.float64)\n",
      "hess: tensor(10.8331)\n",
      "grad: tensor(0.2300, dtype=torch.float64)\n",
      "hess: tensor(5.7349)\n",
      "grad: tensor(0.0380, dtype=torch.float64)\n",
      "hess: tensor(0.9420)\n",
      "grad: tensor(0.3739, dtype=torch.float64)\n",
      "hess: tensor(7.2975)\n",
      "grad: tensor(3.5172, dtype=torch.float64)\n",
      "hess: tensor(43.6167)\n",
      "grad: tensor(0.2186, dtype=torch.float64)\n",
      "hess: tensor(3.2709)\n",
      "grad: tensor(2.4278, dtype=torch.float64)\n",
      "hess: tensor(31.5381)\n",
      "grad: tensor(0.2821, dtype=torch.float64)\n",
      "hess: tensor(5.4832)\n",
      "grad: tensor(2.8666, dtype=torch.float64)\n",
      "hess: tensor(27.3435)\n",
      "grad: tensor(6.8424, dtype=torch.float64)\n",
      "hess: tensor(72.0936)\n",
      "\taccuracy:83.984375\n",
      "\tloss: 0.053319\n",
      "grad: tensor(15.2061, dtype=torch.float64)\n",
      "hess: tensor(152.0421)\n",
      "grad: tensor(0.1846, dtype=torch.float64)\n",
      "hess: tensor(4.6797)\n",
      "grad: tensor(1.6775, dtype=torch.float64)\n",
      "hess: tensor(25.4938)\n",
      "grad: tensor(3.0379, dtype=torch.float64)\n",
      "hess: tensor(50.2707)\n",
      "grad: tensor(7.9957, dtype=torch.float64)\n",
      "hess: tensor(92.7156)\n",
      "grad: tensor(1.1870, dtype=torch.float64)\n",
      "hess: tensor(29.1605)\n",
      "grad: tensor(1.1533, dtype=torch.float64)\n",
      "hess: tensor(17.6567)\n",
      "grad: tensor(3.8193, dtype=torch.float64)\n",
      "hess: tensor(46.4847)\n",
      "grad: tensor(0.1681, dtype=torch.float64)\n",
      "hess: tensor(2.6787)\n",
      "grad: tensor(9.6467, dtype=torch.float64)\n",
      "hess: tensor(120.0377)\n",
      "grad: tensor(8.2110, dtype=torch.float64)\n",
      "hess: tensor(62.7557)\n",
      "grad: tensor(4.4494, dtype=torch.float64)\n",
      "hess: tensor(59.2050)\n",
      "grad: tensor(1.2898, dtype=torch.float64)\n",
      "hess: tensor(23.1950)\n",
      "grad: tensor(0.1382, dtype=torch.float64)\n",
      "hess: tensor(2.9392)\n",
      "grad: tensor(0.0543, dtype=torch.float64)\n",
      "hess: tensor(1.5875)\n",
      "grad: tensor(6.3905, dtype=torch.float64)\n",
      "hess: tensor(58.1634)\n",
      "grad: tensor(0.6475, dtype=torch.float64)\n",
      "hess: tensor(9.9109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d49cd5d436f4dfa9790b43e721ba82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0127, dtype=torch.float64)\n",
      "hess: tensor(0.3780)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000464\n",
      "grad: tensor(0.7513, dtype=torch.float64)\n",
      "hess: tensor(15.1207)\n",
      "grad: tensor(3.3000, dtype=torch.float64)\n",
      "hess: tensor(65.0386)\n",
      "grad: tensor(13.9320, dtype=torch.float64)\n",
      "hess: tensor(57.0249)\n",
      "grad: tensor(3.4147, dtype=torch.float64)\n",
      "hess: tensor(39.0144)\n",
      "grad: tensor(0.4599, dtype=torch.float64)\n",
      "hess: tensor(10.9462)\n",
      "grad: tensor(7.7036, dtype=torch.float64)\n",
      "hess: tensor(69.5767)\n",
      "grad: tensor(0.6569, dtype=torch.float64)\n",
      "hess: tensor(8.3212)\n",
      "grad: tensor(0.1292, dtype=torch.float64)\n",
      "hess: tensor(3.4645)\n",
      "grad: tensor(0.0154, dtype=torch.float64)\n",
      "hess: tensor(0.4021)\n",
      "grad: tensor(0.1697, dtype=torch.float64)\n",
      "hess: tensor(3.6699)\n",
      "grad: tensor(2.8001, dtype=torch.float64)\n",
      "hess: tensor(39.4077)\n",
      "grad: tensor(0.1471, dtype=torch.float64)\n",
      "hess: tensor(2.3891)\n",
      "grad: tensor(2.6254, dtype=torch.float64)\n",
      "hess: tensor(37.4479)\n",
      "grad: tensor(0.1953, dtype=torch.float64)\n",
      "hess: tensor(4.0848)\n",
      "grad: tensor(2.2787, dtype=torch.float64)\n",
      "hess: tensor(24.6405)\n",
      "grad: tensor(5.3759, dtype=torch.float64)\n",
      "hess: tensor(64.9303)\n",
      "\taccuracy:85.15625\n",
      "\tloss: 0.030602\n",
      "grad: tensor(14.0803, dtype=torch.float64)\n",
      "hess: tensor(148.2940)\n",
      "grad: tensor(0.0883, dtype=torch.float64)\n",
      "hess: tensor(2.3874)\n",
      "grad: tensor(1.5143, dtype=torch.float64)\n",
      "hess: tensor(25.2366)\n",
      "grad: tensor(2.6417, dtype=torch.float64)\n",
      "hess: tensor(47.6745)\n",
      "grad: tensor(7.1193, dtype=torch.float64)\n",
      "hess: tensor(91.8069)\n",
      "grad: tensor(0.7811, dtype=torch.float64)\n",
      "hess: tensor(21.3272)\n",
      "grad: tensor(0.7029, dtype=torch.float64)\n",
      "hess: tensor(11.8229)\n",
      "grad: tensor(3.5769, dtype=torch.float64)\n",
      "hess: tensor(47.6599)\n",
      "grad: tensor(0.1233, dtype=torch.float64)\n",
      "hess: tensor(2.0578)\n",
      "grad: tensor(6.1604, dtype=torch.float64)\n",
      "hess: tensor(99.1996)\n",
      "grad: tensor(7.5497, dtype=torch.float64)\n",
      "hess: tensor(65.4615)\n",
      "grad: tensor(3.8048, dtype=torch.float64)\n",
      "hess: tensor(56.0844)\n",
      "grad: tensor(1.0713, dtype=torch.float64)\n",
      "hess: tensor(21.0090)\n",
      "grad: tensor(0.1181, dtype=torch.float64)\n",
      "hess: tensor(2.6858)\n",
      "grad: tensor(0.0253, dtype=torch.float64)\n",
      "hess: tensor(0.7342)\n",
      "grad: tensor(6.1002, dtype=torch.float64)\n",
      "hess: tensor(59.8728)\n",
      "grad: tensor(0.5080, dtype=torch.float64)\n",
      "hess: tensor(8.2963)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d08d0d94744dd29d9926fbc29ebf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0046, dtype=torch.float64)\n",
      "hess: tensor(0.1384)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000163\n",
      "grad: tensor(0.6520, dtype=torch.float64)\n",
      "hess: tensor(13.9003)\n",
      "grad: tensor(3.1405, dtype=torch.float64)\n",
      "hess: tensor(65.6738)\n",
      "grad: tensor(14.4390, dtype=torch.float64)\n",
      "hess: tensor(61.0567)\n",
      "grad: tensor(2.9088, dtype=torch.float64)\n",
      "hess: tensor(36.7095)\n",
      "grad: tensor(0.2453, dtype=torch.float64)\n",
      "hess: tensor(6.2682)\n",
      "grad: tensor(8.9290, dtype=torch.float64)\n",
      "hess: tensor(80.1573)\n",
      "grad: tensor(0.5181, dtype=torch.float64)\n",
      "hess: tensor(6.8708)\n",
      "grad: tensor(0.0864, dtype=torch.float64)\n",
      "hess: tensor(2.4381)\n",
      "grad: tensor(0.0085, dtype=torch.float64)\n",
      "hess: tensor(0.2287)\n",
      "grad: tensor(0.1012, dtype=torch.float64)\n",
      "hess: tensor(2.3447)\n",
      "grad: tensor(2.2582, dtype=torch.float64)\n",
      "hess: tensor(34.9565)\n",
      "grad: tensor(0.1064, dtype=torch.float64)\n",
      "hess: tensor(1.7751)\n",
      "grad: tensor(2.7962, dtype=torch.float64)\n",
      "hess: tensor(41.6233)\n",
      "grad: tensor(0.1436, dtype=torch.float64)\n",
      "hess: tensor(3.1647)\n",
      "grad: tensor(1.9627, dtype=torch.float64)\n",
      "hess: tensor(23.2060)\n",
      "grad: tensor(4.2099, dtype=torch.float64)\n",
      "hess: tensor(56.8429)\n",
      "\taccuracy:86.328125\n",
      "\tloss: 0.019969\n",
      "grad: tensor(12.1312, dtype=torch.float64)\n",
      "hess: tensor(140.7842)\n",
      "grad: tensor(0.0478, dtype=torch.float64)\n",
      "hess: tensor(1.3500)\n",
      "grad: tensor(1.4025, dtype=torch.float64)\n",
      "hess: tensor(25.0206)\n",
      "grad: tensor(2.3942, dtype=torch.float64)\n",
      "hess: tensor(45.9124)\n",
      "grad: tensor(6.3390, dtype=torch.float64)\n",
      "hess: tensor(89.3615)\n",
      "grad: tensor(0.5514, dtype=torch.float64)\n",
      "hess: tensor(16.0986)\n",
      "grad: tensor(0.4499, dtype=torch.float64)\n",
      "hess: tensor(7.9858)\n",
      "grad: tensor(3.1815, dtype=torch.float64)\n",
      "hess: tensor(46.0618)\n",
      "grad: tensor(0.1022, dtype=torch.float64)\n",
      "hess: tensor(1.7659)\n",
      "grad: tensor(3.9115, dtype=torch.float64)\n",
      "hess: tensor(77.8749)\n",
      "grad: tensor(6.8173, dtype=torch.float64)\n",
      "hess: tensor(65.9943)\n",
      "grad: tensor(3.2034, dtype=torch.float64)\n",
      "hess: tensor(51.5333)\n",
      "grad: tensor(0.9680, dtype=torch.float64)\n",
      "hess: tensor(20.2107)\n",
      "grad: tensor(0.1058, dtype=torch.float64)\n",
      "hess: tensor(2.5426)\n",
      "grad: tensor(0.3025, dtype=torch.float64)\n",
      "hess: tensor(9.8792)\n",
      "grad: tensor(5.8711, dtype=torch.float64)\n",
      "hess: tensor(61.2411)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2eb6edca634daea3876c4a2cb0ad7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0020, dtype=torch.float64)\n",
      "hess: tensor(0.0636)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000069\n",
      "grad: tensor(0.4850, dtype=torch.float64)\n",
      "hess: tensor(6.7384)\n",
      "grad: tensor(15.8012, dtype=torch.float64)\n",
      "hess: tensor(155.1491)\n",
      "grad: tensor(2.5120, dtype=torch.float64)\n",
      "hess: tensor(34.2986)\n",
      "grad: tensor(0.3943, dtype=torch.float64)\n",
      "hess: tensor(9.5305)\n",
      "grad: tensor(0.0075, dtype=torch.float64)\n",
      "hess: tensor(0.2032)\n",
      "grad: tensor(0.0636, dtype=torch.float64)\n",
      "hess: tensor(1.8691)\n",
      "grad: tensor(0.2059, dtype=torch.float64)\n",
      "hess: tensor(4.5187)\n",
      "grad: tensor(0.0808, dtype=torch.float64)\n",
      "hess: tensor(1.9828)\n",
      "grad: tensor(0.0840, dtype=torch.float64)\n",
      "hess: tensor(1.4642)\n",
      "grad: tensor(0.4238, dtype=torch.float64)\n",
      "hess: tensor(4.9062)\n",
      "grad: tensor(0.0430, dtype=torch.float64)\n",
      "hess: tensor(1.1464)\n",
      "grad: tensor(3.3167, dtype=torch.float64)\n",
      "hess: tensor(49.2107)\n",
      "\taccuracy:87.109375\n",
      "\tloss: 0.014347\n",
      "grad: tensor(0.0550, dtype=torch.float64)\n",
      "hess: tensor(1.0629)\n",
      "grad: tensor(0.0477, dtype=torch.float64)\n",
      "hess: tensor(1.0158)\n",
      "grad: tensor(2.0797, dtype=torch.float64)\n",
      "hess: tensor(42.2865)\n",
      "grad: tensor(0.4698, dtype=torch.float64)\n",
      "hess: tensor(10.7369)\n",
      "grad: tensor(1.6650, dtype=torch.float64)\n",
      "hess: tensor(38.1350)\n",
      "grad: tensor(3.0187, dtype=torch.float64)\n",
      "hess: tensor(46.0854)\n",
      "grad: tensor(8.8582, dtype=torch.float64)\n",
      "hess: tensor(63.7981)\n",
      "grad: tensor(2.4782, dtype=torch.float64)\n",
      "hess: tensor(35.5661)\n",
      "grad: tensor(2.6956, dtype=torch.float64)\n",
      "hess: tensor(46.6025)\n",
      "grad: tensor(2.1629, dtype=torch.float64)\n",
      "hess: tensor(33.7658)\n",
      "grad: tensor(0.1918, dtype=torch.float64)\n",
      "hess: tensor(6.4832)\n",
      "grad: tensor(5.6800, dtype=torch.float64)\n",
      "hess: tensor(62.2871)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d33732629a4d41985c7a88e7c93116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0317)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000033\n",
      "grad: tensor(0.4291, dtype=torch.float64)\n",
      "hess: tensor(6.1710)\n",
      "grad: tensor(16.7574, dtype=torch.float64)\n",
      "hess: tensor(161.8229)\n",
      "grad: tensor(2.2018, dtype=torch.float64)\n",
      "hess: tensor(32.0465)\n",
      "grad: tensor(0.3228, dtype=torch.float64)\n",
      "hess: tensor(8.2086)\n",
      "grad: tensor(0.0052, dtype=torch.float64)\n",
      "hess: tensor(0.1450)\n",
      "grad: tensor(0.0521, dtype=torch.float64)\n",
      "hess: tensor(1.5756)\n",
      "grad: tensor(0.1440, dtype=torch.float64)\n",
      "hess: tensor(3.3090)\n",
      "grad: tensor(0.0600, dtype=torch.float64)\n",
      "hess: tensor(1.5254)\n",
      "grad: tensor(0.0676, dtype=torch.float64)\n",
      "hess: tensor(1.2247)\n",
      "grad: tensor(0.3697, dtype=torch.float64)\n",
      "hess: tensor(4.3934)\n",
      "grad: tensor(0.0347, dtype=torch.float64)\n",
      "hess: tensor(0.9486)\n",
      "grad: tensor(2.6487, dtype=torch.float64)\n",
      "hess: tensor(42.3472)\n",
      "\taccuracy:87.109375\n",
      "\tloss: 0.010799\n",
      "grad: tensor(0.0373, dtype=torch.float64)\n",
      "hess: tensor(0.7447)\n",
      "grad: tensor(0.0410, dtype=torch.float64)\n",
      "hess: tensor(0.9182)\n",
      "grad: tensor(1.8409, dtype=torch.float64)\n",
      "hess: tensor(39.1851)\n",
      "grad: tensor(0.3637, dtype=torch.float64)\n",
      "hess: tensor(8.6677)\n",
      "grad: tensor(1.5617, dtype=torch.float64)\n",
      "hess: tensor(37.1621)\n",
      "grad: tensor(2.8233, dtype=torch.float64)\n",
      "hess: tensor(45.2354)\n",
      "grad: tensor(8.2554, dtype=torch.float64)\n",
      "hess: tensor(63.7599)\n",
      "grad: tensor(2.3740, dtype=torch.float64)\n",
      "hess: tensor(35.6910)\n",
      "grad: tensor(2.2682, dtype=torch.float64)\n",
      "hess: tensor(41.7076)\n",
      "grad: tensor(2.1781, dtype=torch.float64)\n",
      "hess: tensor(35.1631)\n",
      "grad: tensor(0.1268, dtype=torch.float64)\n",
      "hess: tensor(4.3680)\n",
      "grad: tensor(5.6030, dtype=torch.float64)\n",
      "hess: tensor(63.8295)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949e29486457448f98823e6abf74f566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0005, dtype=torch.float64)\n",
      "hess: tensor(0.0177)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000017\n",
      "grad: tensor(0.3961, dtype=torch.float64)\n",
      "hess: tensor(5.8749)\n",
      "grad: tensor(16.9614, dtype=torch.float64)\n",
      "hess: tensor(163.5779)\n",
      "grad: tensor(1.9567, dtype=torch.float64)\n",
      "hess: tensor(30.0751)\n",
      "grad: tensor(0.2679, dtype=torch.float64)\n",
      "hess: tensor(7.1054)\n",
      "grad: tensor(0.0037, dtype=torch.float64)\n",
      "hess: tensor(0.1075)\n",
      "grad: tensor(0.0449, dtype=torch.float64)\n",
      "hess: tensor(1.3944)\n",
      "grad: tensor(0.1044, dtype=torch.float64)\n",
      "hess: tensor(2.5402)\n",
      "grad: tensor(0.0470, dtype=torch.float64)\n",
      "hess: tensor(1.2330)\n",
      "grad: tensor(0.0548, dtype=torch.float64)\n",
      "hess: tensor(1.0234)\n",
      "grad: tensor(0.3215, dtype=torch.float64)\n",
      "hess: tensor(3.9127)\n",
      "grad: tensor(0.0296, dtype=torch.float64)\n",
      "hess: tensor(0.8292)\n",
      "grad: tensor(2.0682, dtype=torch.float64)\n",
      "hess: tensor(35.4668)\n",
      "\taccuracy:88.28125\n",
      "\tloss: 0.008258\n",
      "grad: tensor(0.0258, dtype=torch.float64)\n",
      "hess: tensor(0.5302)\n",
      "grad: tensor(0.0361, dtype=torch.float64)\n",
      "hess: tensor(0.8403)\n",
      "grad: tensor(1.6350, dtype=torch.float64)\n",
      "hess: tensor(36.2427)\n",
      "grad: tensor(0.2799, dtype=torch.float64)\n",
      "hess: tensor(6.9123)\n",
      "grad: tensor(1.4540, dtype=torch.float64)\n",
      "hess: tensor(35.9042)\n",
      "grad: tensor(2.7833, dtype=torch.float64)\n",
      "hess: tensor(46.0234)\n",
      "grad: tensor(7.5826, dtype=torch.float64)\n",
      "hess: tensor(64.6718)\n",
      "grad: tensor(2.2530, dtype=torch.float64)\n",
      "hess: tensor(35.3590)\n",
      "grad: tensor(1.9091, dtype=torch.float64)\n",
      "hess: tensor(37.0516)\n",
      "grad: tensor(2.3158, dtype=torch.float64)\n",
      "hess: tensor(38.1137)\n",
      "grad: tensor(0.0856, dtype=torch.float64)\n",
      "hess: tensor(2.9774)\n",
      "grad: tensor(5.4658, dtype=torch.float64)\n",
      "hess: tensor(64.7425)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050265564c8d4dab92e6ab99ffbaae28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0102)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000010\n",
      "grad: tensor(0.3725, dtype=torch.float64)\n",
      "hess: tensor(5.6883)\n",
      "grad: tensor(16.9848, dtype=torch.float64)\n",
      "hess: tensor(163.8259)\n",
      "grad: tensor(1.7005, dtype=torch.float64)\n",
      "hess: tensor(27.5211)\n",
      "grad: tensor(0.2324, dtype=torch.float64)\n",
      "hess: tensor(6.3990)\n",
      "grad: tensor(0.0027, dtype=torch.float64)\n",
      "hess: tensor(0.0789)\n",
      "grad: tensor(0.0366, dtype=torch.float64)\n",
      "hess: tensor(1.1395)\n",
      "grad: tensor(0.0751, dtype=torch.float64)\n",
      "hess: tensor(1.8861)\n",
      "grad: tensor(0.0374, dtype=torch.float64)\n",
      "hess: tensor(1.0077)\n",
      "grad: tensor(0.0448, dtype=torch.float64)\n",
      "hess: tensor(0.8618)\n",
      "grad: tensor(0.2854, dtype=torch.float64)\n",
      "hess: tensor(3.5490)\n",
      "grad: tensor(0.0257, dtype=torch.float64)\n",
      "hess: tensor(0.7362)\n",
      "grad: tensor(1.6837, dtype=torch.float64)\n",
      "hess: tensor(30.4495)\n",
      "\taccuracy:88.671875\n",
      "\tloss: 0.006638\n",
      "grad: tensor(0.0189, dtype=torch.float64)\n",
      "hess: tensor(0.3948)\n",
      "grad: tensor(0.0343, dtype=torch.float64)\n",
      "hess: tensor(0.8281)\n",
      "grad: tensor(1.4826, dtype=torch.float64)\n",
      "hess: tensor(34.0532)\n",
      "grad: tensor(0.2233, dtype=torch.float64)\n",
      "hess: tensor(5.6765)\n",
      "grad: tensor(1.3556, dtype=torch.float64)\n",
      "hess: tensor(34.6239)\n",
      "grad: tensor(2.7329, dtype=torch.float64)\n",
      "hess: tensor(46.5717)\n",
      "grad: tensor(7.0532, dtype=torch.float64)\n",
      "hess: tensor(65.1152)\n",
      "grad: tensor(2.1645, dtype=torch.float64)\n",
      "hess: tensor(35.2701)\n",
      "grad: tensor(1.5807, dtype=torch.float64)\n",
      "hess: tensor(32.2448)\n",
      "grad: tensor(2.4464, dtype=torch.float64)\n",
      "hess: tensor(40.7829)\n",
      "grad: tensor(0.0802, dtype=torch.float64)\n",
      "hess: tensor(2.2052)\n",
      "grad: tensor(1.5974, dtype=torch.float64)\n",
      "hess: tensor(26.6995)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468ea42661bd4c34b72519ecfbc7a84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0062)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000006\n",
      "grad: tensor(0.4356, dtype=torch.float64)\n",
      "hess: tensor(6.3598)\n",
      "grad: tensor(15.7868, dtype=torch.float64)\n",
      "hess: tensor(144.5128)\n",
      "grad: tensor(0.0298, dtype=torch.float64)\n",
      "hess: tensor(0.8704)\n",
      "grad: tensor(0.0020, dtype=torch.float64)\n",
      "hess: tensor(0.0602)\n",
      "grad: tensor(10.6108, dtype=torch.float64)\n",
      "hess: tensor(131.6051)\n",
      "grad: tensor(0.0253, dtype=torch.float64)\n",
      "hess: tensor(0.6994)\n",
      "grad: tensor(0.4028, dtype=torch.float64)\n",
      "hess: tensor(10.1712)\n",
      "grad: tensor(0.2548, dtype=torch.float64)\n",
      "hess: tensor(3.2332)\n",
      "grad: tensor(1.6485, dtype=torch.float64)\n",
      "hess: tensor(24.4691)\n",
      "grad: tensor(0.1049, dtype=torch.float64)\n",
      "hess: tensor(2.0065)\n",
      "\taccuracy:88.28125\n",
      "\tloss: 0.005615\n",
      "grad: tensor(7.7291, dtype=torch.float64)\n",
      "hess: tensor(66.7951)\n",
      "grad: tensor(1.3648, dtype=torch.float64)\n",
      "hess: tensor(32.2913)\n",
      "grad: tensor(15.4304, dtype=torch.float64)\n",
      "hess: tensor(91.4263)\n",
      "grad: tensor(0.8383, dtype=torch.float64)\n",
      "hess: tensor(19.1721)\n",
      "grad: tensor(0.0727, dtype=torch.float64)\n",
      "hess: tensor(1.4192)\n",
      "grad: tensor(2.1684, dtype=torch.float64)\n",
      "hess: tensor(36.3019)\n",
      "grad: tensor(9.5924, dtype=torch.float64)\n",
      "hess: tensor(128.4664)\n",
      "grad: tensor(0.0745, dtype=torch.float64)\n",
      "hess: tensor(2.1010)\n",
      "grad: tensor(1.5123, dtype=torch.float64)\n",
      "hess: tensor(26.1016)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fc4faaba6b46858ce173a32d1f1748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(0.0001, dtype=torch.float64)\n",
      "hess: tensor(0.0038)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000003\n",
      "grad: tensor(0.4045, dtype=torch.float64)\n",
      "hess: tensor(6.0592)\n",
      "grad: tensor(14.9998, dtype=torch.float64)\n",
      "hess: tensor(143.4441)\n",
      "grad: tensor(0.0235, dtype=torch.float64)\n",
      "hess: tensor(0.6972)\n",
      "grad: tensor(0.0016, dtype=torch.float64)\n",
      "hess: tensor(0.0492)\n",
      "grad: tensor(9.7708, dtype=torch.float64)\n",
      "hess: tensor(128.7227)\n",
      "grad: tensor(0.0202, dtype=torch.float64)\n",
      "hess: tensor(0.5699)\n",
      "grad: tensor(0.3824, dtype=torch.float64)\n",
      "hess: tensor(9.9045)\n",
      "grad: tensor(0.2276, dtype=torch.float64)\n",
      "hess: tensor(2.9428)\n",
      "grad: tensor(1.7470, dtype=torch.float64)\n",
      "hess: tensor(26.5932)\n",
      "grad: tensor(0.0870, dtype=torch.float64)\n",
      "hess: tensor(1.7121)\n",
      "\taccuracy:88.28125\n",
      "\tloss: 0.004522\n",
      "grad: tensor(7.6955, dtype=torch.float64)\n",
      "hess: tensor(68.7981)\n",
      "grad: tensor(1.2351, dtype=torch.float64)\n",
      "hess: tensor(30.1484)\n",
      "grad: tensor(15.7554, dtype=torch.float64)\n",
      "hess: tensor(96.1117)\n",
      "grad: tensor(0.7228, dtype=torch.float64)\n",
      "hess: tensor(17.1009)\n",
      "grad: tensor(0.0738, dtype=torch.float64)\n",
      "hess: tensor(1.4718)\n",
      "grad: tensor(2.1573, dtype=torch.float64)\n",
      "hess: tensor(37.0562)\n",
      "grad: tensor(9.8819, dtype=torch.float64)\n",
      "hess: tensor(130.4931)\n",
      "grad: tensor(0.0699, dtype=torch.float64)\n",
      "hess: tensor(2.0163)\n",
      "grad: tensor(1.4022, dtype=torch.float64)\n",
      "hess: tensor(25.0086)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9542cad43f4fdab971504ae560cd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(7.3223e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0026)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000002\n",
      "grad: tensor(0.3813, dtype=torch.float64)\n",
      "hess: tensor(5.8518)\n",
      "grad: tensor(14.3552, dtype=torch.float64)\n",
      "hess: tensor(142.9986)\n",
      "grad: tensor(0.0182, dtype=torch.float64)\n",
      "hess: tensor(0.5491)\n",
      "grad: tensor(0.0012, dtype=torch.float64)\n",
      "hess: tensor(0.0378)\n",
      "grad: tensor(8.8869, dtype=torch.float64)\n",
      "hess: tensor(120.3968)\n",
      "grad: tensor(0.0163, dtype=torch.float64)\n",
      "hess: tensor(0.4717)\n",
      "grad: tensor(0.3520, dtype=torch.float64)\n",
      "hess: tensor(9.3369)\n",
      "grad: tensor(0.2018, dtype=torch.float64)\n",
      "hess: tensor(2.6558)\n",
      "grad: tensor(1.7971, dtype=torch.float64)\n",
      "hess: tensor(28.0179)\n",
      "grad: tensor(0.0740, dtype=torch.float64)\n",
      "hess: tensor(1.4955)\n",
      "\taccuracy:88.671875\n",
      "\tloss: 0.003741\n",
      "grad: tensor(7.6910, dtype=torch.float64)\n",
      "hess: tensor(71.0520)\n",
      "grad: tensor(1.1168, dtype=torch.float64)\n",
      "hess: tensor(28.1080)\n",
      "grad: tensor(15.9670, dtype=torch.float64)\n",
      "hess: tensor(101.0754)\n",
      "grad: tensor(0.6135, dtype=torch.float64)\n",
      "hess: tensor(14.9847)\n",
      "grad: tensor(0.0741, dtype=torch.float64)\n",
      "hess: tensor(1.5117)\n",
      "grad: tensor(2.1548, dtype=torch.float64)\n",
      "hess: tensor(37.9228)\n",
      "grad: tensor(9.3272, dtype=torch.float64)\n",
      "hess: tensor(128.8404)\n",
      "grad: tensor(0.0625, dtype=torch.float64)\n",
      "hess: tensor(1.8434)\n",
      "grad: tensor(1.3502, dtype=torch.float64)\n",
      "hess: tensor(24.7082)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055c69dfd91546a3af7ed7c85cee3d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(4.7356e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0017)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000001\n",
      "grad: tensor(0.3636, dtype=torch.float64)\n",
      "hess: tensor(5.7027)\n",
      "grad: tensor(13.3054, dtype=torch.float64)\n",
      "hess: tensor(139.4002)\n",
      "grad: tensor(0.0146, dtype=torch.float64)\n",
      "hess: tensor(0.4490)\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0317)\n",
      "grad: tensor(8.3298, dtype=torch.float64)\n",
      "hess: tensor(121.9097)\n",
      "grad: tensor(0.0130, dtype=torch.float64)\n",
      "hess: tensor(0.3860)\n",
      "grad: tensor(0.3302, dtype=torch.float64)\n",
      "hess: tensor(8.9353)\n",
      "grad: tensor(0.1815, dtype=torch.float64)\n",
      "hess: tensor(2.4447)\n",
      "grad: tensor(1.8400, dtype=torch.float64)\n",
      "hess: tensor(29.3913)\n",
      "grad: tensor(0.0634, dtype=torch.float64)\n",
      "hess: tensor(1.3153)\n",
      "\taccuracy:88.671875\n",
      "\tloss: 0.003121\n",
      "grad: tensor(7.5861, dtype=torch.float64)\n",
      "hess: tensor(72.3276)\n",
      "grad: tensor(1.0352, dtype=torch.float64)\n",
      "hess: tensor(26.7802)\n",
      "grad: tensor(16.1811, dtype=torch.float64)\n",
      "hess: tensor(105.9831)\n",
      "grad: tensor(0.5232, dtype=torch.float64)\n",
      "hess: tensor(13.1590)\n",
      "grad: tensor(0.0728, dtype=torch.float64)\n",
      "hess: tensor(1.5209)\n",
      "grad: tensor(2.1507, dtype=torch.float64)\n",
      "hess: tensor(38.7071)\n",
      "grad: tensor(9.1721, dtype=torch.float64)\n",
      "hess: tensor(128.8084)\n",
      "grad: tensor(0.0570, dtype=torch.float64)\n",
      "hess: tensor(1.7143)\n",
      "grad: tensor(1.2949, dtype=torch.float64)\n",
      "hess: tensor(24.2996)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99ee6e4f3154ba2819bae41ed2862f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(3.2702e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0012)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000001\n",
      "grad: tensor(0.3513, dtype=torch.float64)\n",
      "hess: tensor(5.6084)\n",
      "grad: tensor(12.4569, dtype=torch.float64)\n",
      "hess: tensor(136.4137)\n",
      "grad: tensor(0.0120, dtype=torch.float64)\n",
      "hess: tensor(0.3761)\n",
      "grad: tensor(0.0008, dtype=torch.float64)\n",
      "hess: tensor(0.0263)\n",
      "grad: tensor(7.8842, dtype=torch.float64)\n",
      "hess: tensor(120.2331)\n",
      "grad: tensor(0.0100, dtype=torch.float64)\n",
      "hess: tensor(0.3021)\n",
      "grad: tensor(0.3087, dtype=torch.float64)\n",
      "hess: tensor(8.5398)\n",
      "grad: tensor(0.1638, dtype=torch.float64)\n",
      "hess: tensor(2.2413)\n",
      "grad: tensor(1.8610, dtype=torch.float64)\n",
      "hess: tensor(30.4254)\n",
      "grad: tensor(0.0543, dtype=torch.float64)\n",
      "hess: tensor(1.1535)\n",
      "\taccuracy:89.0625\n",
      "\tloss: 0.002605\n",
      "grad: tensor(7.4416, dtype=torch.float64)\n",
      "hess: tensor(73.3108)\n",
      "grad: tensor(0.9421, dtype=torch.float64)\n",
      "hess: tensor(25.0544)\n",
      "grad: tensor(16.1813, dtype=torch.float64)\n",
      "hess: tensor(110.9274)\n",
      "grad: tensor(0.4472, dtype=torch.float64)\n",
      "hess: tensor(11.5503)\n",
      "grad: tensor(0.0731, dtype=torch.float64)\n",
      "hess: tensor(1.5602)\n",
      "grad: tensor(2.1884, dtype=torch.float64)\n",
      "hess: tensor(40.1083)\n",
      "grad: tensor(9.1760, dtype=torch.float64)\n",
      "hess: tensor(129.3837)\n",
      "grad: tensor(0.0518, dtype=torch.float64)\n",
      "hess: tensor(1.5899)\n",
      "grad: tensor(4.4759, dtype=torch.float64)\n",
      "hess: tensor(64.3563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc2153b18304120a78f3235f2c32b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.4132e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0009)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000001\n",
      "grad: tensor(0.8875, dtype=torch.float64)\n",
      "hess: tensor(29.5173)\n",
      "grad: tensor(0.6725, dtype=torch.float64)\n",
      "hess: tensor(12.7534)\n",
      "grad: tensor(10.0433, dtype=torch.float64)\n",
      "hess: tensor(114.7950)\n",
      "grad: tensor(0.0149, dtype=torch.float64)\n",
      "hess: tensor(0.5147)\n",
      "grad: tensor(0.0080, dtype=torch.float64)\n",
      "hess: tensor(0.2487)\n",
      "grad: tensor(0.0132, dtype=torch.float64)\n",
      "hess: tensor(0.2919)\n",
      "grad: tensor(0.0290, dtype=torch.float64)\n",
      "hess: tensor(0.8273)\n",
      "grad: tensor(0.5475, dtype=torch.float64)\n",
      "hess: tensor(12.0733)\n",
      "\taccuracy:89.0625\n",
      "\tloss: 0.002191\n",
      "grad: tensor(0.0034, dtype=torch.float64)\n",
      "hess: tensor(0.1192)\n",
      "grad: tensor(0.8505, dtype=torch.float64)\n",
      "hess: tensor(23.2615)\n",
      "grad: tensor(0.1273, dtype=torch.float64)\n",
      "hess: tensor(4.8661)\n",
      "grad: tensor(2.1218, dtype=torch.float64)\n",
      "hess: tensor(42.7726)\n",
      "grad: tensor(0.0598, dtype=torch.float64)\n",
      "hess: tensor(2.2628)\n",
      "grad: tensor(0.5977, dtype=torch.float64)\n",
      "hess: tensor(14.8643)\n",
      "grad: tensor(0.0454, dtype=torch.float64)\n",
      "hess: tensor(1.4194)\n",
      "grad: tensor(4.3017, dtype=torch.float64)\n",
      "hess: tensor(63.6237)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5289481d6b9406db311e38cb92bb3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.7707e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0007)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.7191, dtype=torch.float64)\n",
      "hess: tensor(24.8650)\n",
      "grad: tensor(0.6136, dtype=torch.float64)\n",
      "hess: tensor(11.8649)\n",
      "grad: tensor(9.4586, dtype=torch.float64)\n",
      "hess: tensor(113.2425)\n",
      "grad: tensor(0.0127, dtype=torch.float64)\n",
      "hess: tensor(0.4461)\n",
      "grad: tensor(0.0064, dtype=torch.float64)\n",
      "hess: tensor(0.2023)\n",
      "grad: tensor(0.0111, dtype=torch.float64)\n",
      "hess: tensor(0.2490)\n",
      "grad: tensor(0.0249, dtype=torch.float64)\n",
      "hess: tensor(0.7207)\n",
      "grad: tensor(0.4627, dtype=torch.float64)\n",
      "hess: tensor(10.4186)\n",
      "\taccuracy:89.453125\n",
      "\tloss: 0.001802\n",
      "grad: tensor(0.0032, dtype=torch.float64)\n",
      "hess: tensor(0.1123)\n",
      "grad: tensor(0.7906, dtype=torch.float64)\n",
      "hess: tensor(22.1613)\n",
      "grad: tensor(0.1200, dtype=torch.float64)\n",
      "hess: tensor(4.6514)\n",
      "grad: tensor(2.0193, dtype=torch.float64)\n",
      "hess: tensor(41.7320)\n",
      "grad: tensor(0.0443, dtype=torch.float64)\n",
      "hess: tensor(1.7069)\n",
      "grad: tensor(0.5252, dtype=torch.float64)\n",
      "hess: tensor(13.3549)\n",
      "grad: tensor(0.0398, dtype=torch.float64)\n",
      "hess: tensor(1.2648)\n",
      "grad: tensor(4.1344, dtype=torch.float64)\n",
      "hess: tensor(62.8231)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182f3a1778ba48be8dece4ebaf92ebe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.3707e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0006)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.5762, dtype=torch.float64)\n",
      "hess: tensor(20.6275)\n",
      "grad: tensor(0.5521, dtype=torch.float64)\n",
      "hess: tensor(10.8807)\n",
      "grad: tensor(8.7673, dtype=torch.float64)\n",
      "hess: tensor(110.7119)\n",
      "grad: tensor(0.0114, dtype=torch.float64)\n",
      "hess: tensor(0.4044)\n",
      "grad: tensor(0.0049, dtype=torch.float64)\n",
      "hess: tensor(0.1585)\n",
      "grad: tensor(0.0088, dtype=torch.float64)\n",
      "hess: tensor(0.2004)\n",
      "grad: tensor(0.0222, dtype=torch.float64)\n",
      "hess: tensor(0.6543)\n",
      "grad: tensor(0.4085, dtype=torch.float64)\n",
      "hess: tensor(9.3939)\n",
      "\taccuracy:89.0625\n",
      "\tloss: 0.001541\n",
      "grad: tensor(0.0028, dtype=torch.float64)\n",
      "hess: tensor(0.1025)\n",
      "grad: tensor(0.7300, dtype=torch.float64)\n",
      "hess: tensor(20.9769)\n",
      "grad: tensor(0.1117, dtype=torch.float64)\n",
      "hess: tensor(4.3934)\n",
      "grad: tensor(1.9506, dtype=torch.float64)\n",
      "hess: tensor(41.2333)\n",
      "grad: tensor(0.0330, dtype=torch.float64)\n",
      "hess: tensor(1.2943)\n",
      "grad: tensor(0.4760, dtype=torch.float64)\n",
      "hess: tensor(12.3805)\n",
      "grad: tensor(0.0348, dtype=torch.float64)\n",
      "hess: tensor(1.1265)\n",
      "grad: tensor(3.9647, dtype=torch.float64)\n",
      "hess: tensor(61.8939)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0566319f9f49f683231cd48f135ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(9.9476e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0005)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.4753, dtype=torch.float64)\n",
      "hess: tensor(17.5294)\n",
      "grad: tensor(0.4944, dtype=torch.float64)\n",
      "hess: tensor(9.9359)\n",
      "grad: tensor(8.0112, dtype=torch.float64)\n",
      "hess: tensor(107.3242)\n",
      "grad: tensor(0.0099, dtype=torch.float64)\n",
      "hess: tensor(0.3590)\n",
      "grad: tensor(0.0039, dtype=torch.float64)\n",
      "hess: tensor(0.1277)\n",
      "grad: tensor(0.0072, dtype=torch.float64)\n",
      "hess: tensor(0.1675)\n",
      "grad: tensor(0.0199, dtype=torch.float64)\n",
      "hess: tensor(0.5972)\n",
      "grad: tensor(0.3497, dtype=torch.float64)\n",
      "hess: tensor(8.1809)\n",
      "\taccuracy:89.0625\n",
      "\tloss: 0.001297\n",
      "grad: tensor(0.0026, dtype=torch.float64)\n",
      "hess: tensor(0.0957)\n",
      "grad: tensor(0.6793, dtype=torch.float64)\n",
      "hess: tensor(19.9939)\n",
      "grad: tensor(0.1041, dtype=torch.float64)\n",
      "hess: tensor(4.1809)\n",
      "grad: tensor(1.8318, dtype=torch.float64)\n",
      "hess: tensor(39.7500)\n",
      "grad: tensor(0.0269, dtype=torch.float64)\n",
      "hess: tensor(1.0728)\n",
      "grad: tensor(0.4320, dtype=torch.float64)\n",
      "hess: tensor(11.4484)\n",
      "grad: tensor(0.0291, dtype=torch.float64)\n",
      "hess: tensor(0.9571)\n",
      "grad: tensor(3.8064, dtype=torch.float64)\n",
      "hess: tensor(60.9544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9a752b3f3748159093404ba85a2b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(6.3064e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0003)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.3924, dtype=torch.float64)\n",
      "hess: tensor(14.8651)\n",
      "grad: tensor(0.4458, dtype=torch.float64)\n",
      "hess: tensor(9.1276)\n",
      "grad: tensor(7.5204, dtype=torch.float64)\n",
      "hess: tensor(105.3076)\n",
      "grad: tensor(0.0083, dtype=torch.float64)\n",
      "hess: tensor(0.3040)\n",
      "grad: tensor(0.0033, dtype=torch.float64)\n",
      "hess: tensor(0.1095)\n",
      "grad: tensor(0.0060, dtype=torch.float64)\n",
      "hess: tensor(0.1415)\n",
      "grad: tensor(0.0173, dtype=torch.float64)\n",
      "hess: tensor(0.5267)\n",
      "grad: tensor(0.3019, dtype=torch.float64)\n",
      "hess: tensor(7.1877)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.001071\n",
      "grad: tensor(0.0025, dtype=torch.float64)\n",
      "hess: tensor(0.0912)\n",
      "grad: tensor(0.6229, dtype=torch.float64)\n",
      "hess: tensor(18.7525)\n",
      "grad: tensor(0.0979, dtype=torch.float64)\n",
      "hess: tensor(3.9503)\n",
      "grad: tensor(1.7779, dtype=torch.float64)\n",
      "hess: tensor(39.3211)\n",
      "grad: tensor(0.0213, dtype=torch.float64)\n",
      "hess: tensor(0.8624)\n",
      "grad: tensor(0.3984, dtype=torch.float64)\n",
      "hess: tensor(10.7464)\n",
      "grad: tensor(0.0259, dtype=torch.float64)\n",
      "hess: tensor(0.8621)\n",
      "grad: tensor(3.6826, dtype=torch.float64)\n",
      "hess: tensor(60.2975)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b917e172a7564718b13c0bb47cc306ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(5.7153e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0003)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.3157, dtype=torch.float64)\n",
      "hess: tensor(12.2601)\n",
      "grad: tensor(0.4086, dtype=torch.float64)\n",
      "hess: tensor(8.5061)\n",
      "grad: tensor(6.7813, dtype=torch.float64)\n",
      "hess: tensor(101.0414)\n",
      "grad: tensor(0.0075, dtype=torch.float64)\n",
      "hess: tensor(0.2800)\n",
      "grad: tensor(0.0026, dtype=torch.float64)\n",
      "hess: tensor(0.0884)\n",
      "grad: tensor(0.0049, dtype=torch.float64)\n",
      "hess: tensor(0.1171)\n",
      "grad: tensor(0.0154, dtype=torch.float64)\n",
      "hess: tensor(0.4763)\n",
      "grad: tensor(0.2642, dtype=torch.float64)\n",
      "hess: tensor(6.4118)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000887\n",
      "grad: tensor(0.0023, dtype=torch.float64)\n",
      "hess: tensor(0.0854)\n",
      "grad: tensor(0.5864, dtype=torch.float64)\n",
      "hess: tensor(18.0222)\n",
      "grad: tensor(0.0932, dtype=torch.float64)\n",
      "hess: tensor(3.8376)\n",
      "grad: tensor(1.7056, dtype=torch.float64)\n",
      "hess: tensor(38.5211)\n",
      "grad: tensor(0.2730, dtype=torch.float64)\n",
      "hess: tensor(9.6250)\n",
      "grad: tensor(0.3648, dtype=torch.float64)\n",
      "hess: tensor(10.0353)\n",
      "grad: tensor(0.0501, dtype=torch.float64)\n",
      "hess: tensor(1.7972)\n",
      "grad: tensor(1.2892, dtype=torch.float64)\n",
      "hess: tensor(35.2724)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c896d437eb43b480795cd9f8d4f50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(5.1519e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0745, dtype=torch.float64)\n",
      "hess: tensor(1.9229)\n",
      "grad: tensor(10.6120, dtype=torch.float64)\n",
      "hess: tensor(93.9147)\n",
      "grad: tensor(0.3852, dtype=torch.float64)\n",
      "hess: tensor(6.7345)\n",
      "grad: tensor(0.0054, dtype=torch.float64)\n",
      "hess: tensor(0.1778)\n",
      "grad: tensor(0.2371, dtype=torch.float64)\n",
      "hess: tensor(7.4107)\n",
      "grad: tensor(0.0138, dtype=torch.float64)\n",
      "hess: tensor(0.4306)\n",
      "grad: tensor(0.0096, dtype=torch.float64)\n",
      "hess: tensor(0.2836)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000763\n",
      "grad: tensor(0.0177, dtype=torch.float64)\n",
      "hess: tensor(0.5517)\n",
      "grad: tensor(3.9107, dtype=torch.float64)\n",
      "hess: tensor(87.1342)\n",
      "grad: tensor(0.1669, dtype=torch.float64)\n",
      "hess: tensor(4.9553)\n",
      "grad: tensor(0.2534, dtype=torch.float64)\n",
      "hess: tensor(9.0455)\n",
      "grad: tensor(0.3440, dtype=torch.float64)\n",
      "hess: tensor(9.6301)\n",
      "grad: tensor(0.0505, dtype=torch.float64)\n",
      "hess: tensor(1.8319)\n",
      "grad: tensor(1.2860, dtype=torch.float64)\n",
      "hess: tensor(35.6844)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9087fc3181914ba5a781e02a93fd7be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(4.9176e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0704, dtype=torch.float64)\n",
      "hess: tensor(1.8450)\n",
      "grad: tensor(10.4037, dtype=torch.float64)\n",
      "hess: tensor(94.2437)\n",
      "grad: tensor(0.4084, dtype=torch.float64)\n",
      "hess: tensor(7.2286)\n",
      "grad: tensor(0.0047, dtype=torch.float64)\n",
      "hess: tensor(0.1556)\n",
      "grad: tensor(0.2300, dtype=torch.float64)\n",
      "hess: tensor(7.3138)\n",
      "grad: tensor(0.0123, dtype=torch.float64)\n",
      "hess: tensor(0.3917)\n",
      "grad: tensor(0.0078, dtype=torch.float64)\n",
      "hess: tensor(0.2148)\n",
      "\taccuracy:89.0625\n",
      "\tloss: 0.000648\n",
      "grad: tensor(0.0166, dtype=torch.float64)\n",
      "hess: tensor(0.5267)\n",
      "grad: tensor(3.8872, dtype=torch.float64)\n",
      "hess: tensor(87.5763)\n",
      "grad: tensor(0.1475, dtype=torch.float64)\n",
      "hess: tensor(4.4495)\n",
      "grad: tensor(0.2609, dtype=torch.float64)\n",
      "hess: tensor(9.4397)\n",
      "grad: tensor(0.3421, dtype=torch.float64)\n",
      "hess: tensor(9.7162)\n",
      "grad: tensor(0.0488, dtype=torch.float64)\n",
      "hess: tensor(1.7897)\n",
      "grad: tensor(1.2278, dtype=torch.float64)\n",
      "hess: tensor(34.7078)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f7f4be7d8343daad77965c6048b773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(4.7040e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0657, dtype=torch.float64)\n",
      "hess: tensor(1.7384)\n",
      "grad: tensor(10.1244, dtype=torch.float64)\n",
      "hess: tensor(93.9364)\n",
      "grad: tensor(0.4320, dtype=torch.float64)\n",
      "hess: tensor(7.7575)\n",
      "grad: tensor(0.0039, dtype=torch.float64)\n",
      "hess: tensor(0.1327)\n",
      "grad: tensor(0.2213, dtype=torch.float64)\n",
      "hess: tensor(7.1383)\n",
      "grad: tensor(0.0110, dtype=torch.float64)\n",
      "hess: tensor(0.3522)\n",
      "grad: tensor(0.0067, dtype=torch.float64)\n",
      "hess: tensor(0.2030)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000545\n",
      "grad: tensor(0.0148, dtype=torch.float64)\n",
      "hess: tensor(0.4758)\n",
      "grad: tensor(3.6917, dtype=torch.float64)\n",
      "hess: tensor(85.4377)\n",
      "grad: tensor(0.1288, dtype=torch.float64)\n",
      "hess: tensor(3.9438)\n",
      "grad: tensor(0.2461, dtype=torch.float64)\n",
      "hess: tensor(9.0188)\n",
      "grad: tensor(0.3170, dtype=torch.float64)\n",
      "hess: tensor(9.1640)\n",
      "grad: tensor(0.0472, dtype=torch.float64)\n",
      "hess: tensor(1.7496)\n",
      "grad: tensor(1.2290, dtype=torch.float64)\n",
      "hess: tensor(35.1897)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a32200ed2af4199823d9c1c9139fc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.8448e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0001)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0627, dtype=torch.float64)\n",
      "hess: tensor(1.6793)\n",
      "grad: tensor(9.6001, dtype=torch.float64)\n",
      "hess: tensor(92.4618)\n",
      "grad: tensor(0.4564, dtype=torch.float64)\n",
      "hess: tensor(8.3113)\n",
      "grad: tensor(0.0034, dtype=torch.float64)\n",
      "hess: tensor(0.1147)\n",
      "grad: tensor(0.2075, dtype=torch.float64)\n",
      "hess: tensor(6.7721)\n",
      "grad: tensor(0.0096, dtype=torch.float64)\n",
      "hess: tensor(0.3120)\n",
      "grad: tensor(0.0059, dtype=torch.float64)\n",
      "hess: tensor(0.1794)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000474\n",
      "grad: tensor(0.0140, dtype=torch.float64)\n",
      "hess: tensor(0.4541)\n",
      "grad: tensor(3.5160, dtype=torch.float64)\n",
      "hess: tensor(83.4614)\n",
      "grad: tensor(0.1185, dtype=torch.float64)\n",
      "hess: tensor(3.6793)\n",
      "grad: tensor(0.2442, dtype=torch.float64)\n",
      "hess: tensor(9.0619)\n",
      "grad: tensor(0.3062, dtype=torch.float64)\n",
      "hess: tensor(8.9721)\n",
      "grad: tensor(0.0474, dtype=torch.float64)\n",
      "hess: tensor(1.7776)\n",
      "grad: tensor(1.1794, dtype=torch.float64)\n",
      "hess: tensor(34.3088)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc2aa95935744b5857aa74449ebe1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.4685e-06, dtype=torch.float64)\n",
      "hess: tensor(9.1883e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0583, dtype=torch.float64)\n",
      "hess: tensor(1.5790)\n",
      "grad: tensor(9.4259, dtype=torch.float64)\n",
      "hess: tensor(92.5153)\n",
      "grad: tensor(0.4715, dtype=torch.float64)\n",
      "hess: tensor(8.7226)\n",
      "grad: tensor(0.0028, dtype=torch.float64)\n",
      "hess: tensor(0.0972)\n",
      "grad: tensor(0.1996, dtype=torch.float64)\n",
      "hess: tensor(6.6200)\n",
      "grad: tensor(0.0089, dtype=torch.float64)\n",
      "hess: tensor(0.2940)\n",
      "grad: tensor(0.0046, dtype=torch.float64)\n",
      "hess: tensor(0.1296)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000409\n",
      "grad: tensor(0.0133, dtype=torch.float64)\n",
      "hess: tensor(0.4399)\n",
      "grad: tensor(3.3464, dtype=torch.float64)\n",
      "hess: tensor(81.4292)\n",
      "grad: tensor(0.1063, dtype=torch.float64)\n",
      "hess: tensor(3.3451)\n",
      "grad: tensor(0.2388, dtype=torch.float64)\n",
      "hess: tensor(8.9621)\n",
      "grad: tensor(0.3038, dtype=torch.float64)\n",
      "hess: tensor(9.0157)\n",
      "grad: tensor(0.0481, dtype=torch.float64)\n",
      "hess: tensor(1.8267)\n",
      "grad: tensor(1.1273, dtype=torch.float64)\n",
      "hess: tensor(33.4405)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c008f354f5644491ad253631bedc42e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.2843e-06, dtype=torch.float64)\n",
      "hess: tensor(7.8884e-05)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0544, dtype=torch.float64)\n",
      "hess: tensor(1.4835)\n",
      "grad: tensor(8.9972, dtype=torch.float64)\n",
      "hess: tensor(91.0157)\n",
      "grad: tensor(0.4858, dtype=torch.float64)\n",
      "hess: tensor(9.1514)\n",
      "grad: tensor(0.0024, dtype=torch.float64)\n",
      "hess: tensor(0.0825)\n",
      "grad: tensor(0.1868, dtype=torch.float64)\n",
      "hess: tensor(6.2548)\n",
      "grad: tensor(0.0081, dtype=torch.float64)\n",
      "hess: tensor(0.2677)\n",
      "grad: tensor(0.0040, dtype=torch.float64)\n",
      "hess: tensor(0.1136)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000345\n",
      "grad: tensor(0.0119, dtype=torch.float64)\n",
      "hess: tensor(0.3985)\n",
      "grad: tensor(3.1914, dtype=torch.float64)\n",
      "hess: tensor(79.4597)\n",
      "grad: tensor(0.0962, dtype=torch.float64)\n",
      "hess: tensor(3.0670)\n",
      "grad: tensor(0.2410, dtype=torch.float64)\n",
      "hess: tensor(9.1545)\n",
      "grad: tensor(0.3153, dtype=torch.float64)\n",
      "hess: tensor(9.5012)\n",
      "grad: tensor(0.0492, dtype=torch.float64)\n",
      "hess: tensor(1.8855)\n",
      "grad: tensor(1.0942, dtype=torch.float64)\n",
      "hess: tensor(32.9263)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e5440ff49141b696a1053ea1fe25aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.0185e-06, dtype=torch.float64)\n",
      "hess: tensor(5.9684e-05)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0515, dtype=torch.float64)\n",
      "hess: tensor(1.4216)\n",
      "grad: tensor(8.6907, dtype=torch.float64)\n",
      "hess: tensor(90.0077)\n",
      "grad: tensor(0.5152, dtype=torch.float64)\n",
      "hess: tensor(9.8286)\n",
      "grad: tensor(0.0020, dtype=torch.float64)\n",
      "hess: tensor(0.0707)\n",
      "grad: tensor(0.1797, dtype=torch.float64)\n",
      "hess: tensor(6.0949)\n",
      "grad: tensor(0.0479, dtype=torch.float64)\n",
      "hess: tensor(0.7660)\n",
      "grad: tensor(0.1310, dtype=torch.float64)\n",
      "hess: tensor(3.5247)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000298\n",
      "grad: tensor(0.0108, dtype=torch.float64)\n",
      "hess: tensor(0.3651)\n",
      "grad: tensor(0.0203, dtype=torch.float64)\n",
      "hess: tensor(0.6765)\n",
      "grad: tensor(1.2033, dtype=torch.float64)\n",
      "hess: tensor(30.6375)\n",
      "grad: tensor(2.0126, dtype=torch.float64)\n",
      "hess: tensor(45.6293)\n",
      "grad: tensor(3.6498, dtype=torch.float64)\n",
      "hess: tensor(71.9626)\n",
      "grad: tensor(2.3519, dtype=torch.float64)\n",
      "hess: tensor(46.7475)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2b0d496eb743038acc0b3e289d36b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(9.0401e-07, dtype=torch.float64)\n",
      "hess: tensor(5.4076e-05)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.9960, dtype=torch.float64)\n",
      "hess: tensor(116.2932)\n",
      "grad: tensor(0.0329, dtype=torch.float64)\n",
      "hess: tensor(1.3106)\n",
      "grad: tensor(0.0040, dtype=torch.float64)\n",
      "hess: tensor(0.1601)\n",
      "grad: tensor(0.0067, dtype=torch.float64)\n",
      "hess: tensor(0.2585)\n",
      "grad: tensor(0.0439, dtype=torch.float64)\n",
      "hess: tensor(0.7081)\n",
      "grad: tensor(0.1166, dtype=torch.float64)\n",
      "hess: tensor(3.1782)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000259\n",
      "grad: tensor(0.0098, dtype=torch.float64)\n",
      "hess: tensor(0.3351)\n",
      "grad: tensor(0.0188, dtype=torch.float64)\n",
      "hess: tensor(0.6317)\n",
      "grad: tensor(1.0653, dtype=torch.float64)\n",
      "hess: tensor(27.7799)\n",
      "grad: tensor(1.9339, dtype=torch.float64)\n",
      "hess: tensor(44.6625)\n",
      "grad: tensor(3.9360, dtype=torch.float64)\n",
      "hess: tensor(79.9969)\n",
      "grad: tensor(2.2765, dtype=torch.float64)\n",
      "hess: tensor(45.9001)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a1d5c4ee3243bf98f938a5949577b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(7.2882e-07, dtype=torch.float64)\n",
      "hess: tensor(4.3693e-05)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.6738, dtype=torch.float64)\n",
      "hess: tensor(114.0902)\n",
      "grad: tensor(0.0324, dtype=torch.float64)\n",
      "hess: tensor(1.3073)\n",
      "grad: tensor(0.0037, dtype=torch.float64)\n",
      "hess: tensor(0.1525)\n",
      "grad: tensor(0.0068, dtype=torch.float64)\n",
      "hess: tensor(0.2668)\n",
      "grad: tensor(0.0408, dtype=torch.float64)\n",
      "hess: tensor(0.6615)\n",
      "grad: tensor(0.1088, dtype=torch.float64)\n",
      "hess: tensor(2.9959)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000226\n",
      "grad: tensor(0.0093, dtype=torch.float64)\n",
      "hess: tensor(0.3216)\n",
      "grad: tensor(0.0175, dtype=torch.float64)\n",
      "hess: tensor(0.5931)\n",
      "grad: tensor(1.0414, dtype=torch.float64)\n",
      "hess: tensor(27.5179)\n",
      "grad: tensor(1.8988, dtype=torch.float64)\n",
      "hess: tensor(44.4607)\n",
      "grad: tensor(4.1263, dtype=torch.float64)\n",
      "hess: tensor(83.1256)\n",
      "grad: tensor(2.0979, dtype=torch.float64)\n",
      "hess: tensor(43.3346)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffea224290d4f1faaae4e04ad5f6a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(6.4344e-07, dtype=torch.float64)\n",
      "hess: tensor(3.9524e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.3820, dtype=torch.float64)\n",
      "hess: tensor(112.0091)\n",
      "grad: tensor(0.0260, dtype=torch.float64)\n",
      "hess: tensor(1.0606)\n",
      "grad: tensor(0.0035, dtype=torch.float64)\n",
      "hess: tensor(0.1439)\n",
      "grad: tensor(0.0062, dtype=torch.float64)\n",
      "hess: tensor(0.2425)\n",
      "grad: tensor(0.0382, dtype=torch.float64)\n",
      "hess: tensor(0.6257)\n",
      "grad: tensor(0.0989, dtype=torch.float64)\n",
      "hess: tensor(2.7560)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000195\n",
      "grad: tensor(0.0086, dtype=torch.float64)\n",
      "hess: tensor(0.2998)\n",
      "grad: tensor(0.0163, dtype=torch.float64)\n",
      "hess: tensor(0.5575)\n",
      "grad: tensor(1.0053, dtype=torch.float64)\n",
      "hess: tensor(26.9261)\n",
      "grad: tensor(1.7687, dtype=torch.float64)\n",
      "hess: tensor(42.3713)\n",
      "grad: tensor(3.8647, dtype=torch.float64)\n",
      "hess: tensor(80.3648)\n",
      "grad: tensor(1.9763, dtype=torch.float64)\n",
      "hess: tensor(41.5769)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bfc87641724facafa2ccdceebbb285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(5.1307e-07, dtype=torch.float64)\n",
      "hess: tensor(3.3112e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.2646, dtype=torch.float64)\n",
      "hess: tensor(111.3574)\n",
      "grad: tensor(0.0270, dtype=torch.float64)\n",
      "hess: tensor(1.1131)\n",
      "grad: tensor(0.0034, dtype=torch.float64)\n",
      "hess: tensor(0.1411)\n",
      "grad: tensor(0.0061, dtype=torch.float64)\n",
      "hess: tensor(0.2424)\n",
      "grad: tensor(0.0357, dtype=torch.float64)\n",
      "hess: tensor(0.5876)\n",
      "grad: tensor(0.0931, dtype=torch.float64)\n",
      "hess: tensor(2.6155)\n",
      "\taccuracy:89.84375\n",
      "\tloss: 0.000175\n",
      "grad: tensor(0.0081, dtype=torch.float64)\n",
      "hess: tensor(0.2870)\n",
      "grad: tensor(0.0152, dtype=torch.float64)\n",
      "hess: tensor(0.5234)\n",
      "grad: tensor(0.9385, dtype=torch.float64)\n",
      "hess: tensor(25.5289)\n",
      "grad: tensor(1.7164, dtype=torch.float64)\n",
      "hess: tensor(41.7329)\n",
      "grad: tensor(4.0706, dtype=torch.float64)\n",
      "hess: tensor(83.7186)\n",
      "grad: tensor(1.8674, dtype=torch.float64)\n",
      "hess: tensor(39.9823)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5686c35432c43798f7525ca1fcffd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(4.5270e-07, dtype=torch.float64)\n",
      "hess: tensor(3.0155e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.1081, dtype=torch.float64)\n",
      "hess: tensor(110.3401)\n",
      "grad: tensor(0.0244, dtype=torch.float64)\n",
      "hess: tensor(1.0199)\n",
      "grad: tensor(0.0032, dtype=torch.float64)\n",
      "hess: tensor(0.1339)\n",
      "grad: tensor(0.0056, dtype=torch.float64)\n",
      "hess: tensor(0.2258)\n",
      "grad: tensor(0.0339, dtype=torch.float64)\n",
      "hess: tensor(0.5616)\n",
      "grad: tensor(0.0872, dtype=torch.float64)\n",
      "hess: tensor(2.4780)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000152\n",
      "grad: tensor(0.0078, dtype=torch.float64)\n",
      "hess: tensor(0.2776)\n",
      "grad: tensor(0.0142, dtype=torch.float64)\n",
      "hess: tensor(0.4922)\n",
      "grad: tensor(0.8923, dtype=torch.float64)\n",
      "hess: tensor(24.6107)\n",
      "grad: tensor(1.6149, dtype=torch.float64)\n",
      "hess: tensor(40.0460)\n",
      "grad: tensor(3.8031, dtype=torch.float64)\n",
      "hess: tensor(80.7714)\n",
      "grad: tensor(1.7357, dtype=torch.float64)\n",
      "hess: tensor(37.8956)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedf30eff92d423a8244c5c1246b65cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(3.6259e-07, dtype=torch.float64)\n",
      "hess: tensor(2.2228e-05)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(4.8508, dtype=torch.float64)\n",
      "hess: tensor(108.1689)\n",
      "grad: tensor(0.0198, dtype=torch.float64)\n",
      "hess: tensor(0.8359)\n",
      "grad: tensor(0.0033, dtype=torch.float64)\n",
      "hess: tensor(0.1374)\n",
      "grad: tensor(0.0058, dtype=torch.float64)\n",
      "hess: tensor(0.2366)\n",
      "grad: tensor(0.0322, dtype=torch.float64)\n",
      "hess: tensor(0.5372)\n",
      "grad: tensor(0.0808, dtype=torch.float64)\n",
      "hess: tensor(2.3078)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000137\n",
      "grad: tensor(0.0075, dtype=torch.float64)\n",
      "hess: tensor(0.2706)\n",
      "grad: tensor(0.0136, dtype=torch.float64)\n",
      "hess: tensor(0.4749)\n",
      "grad: tensor(0.9788, dtype=torch.float64)\n",
      "hess: tensor(23.3069)\n",
      "grad: tensor(1.6376, dtype=torch.float64)\n",
      "hess: tensor(40.8401)\n",
      "grad: tensor(3.9103, dtype=torch.float64)\n",
      "hess: tensor(82.7851)\n",
      "grad: tensor(1.6164, dtype=torch.float64)\n",
      "hess: tensor(35.9233)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4283e4981f4d6393c8b5ef23d60f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(3.3235e-07, dtype=torch.float64)\n",
      "hess: tensor(2.0684e-05)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(4.5913, dtype=torch.float64)\n",
      "hess: tensor(105.8161)\n",
      "grad: tensor(0.0175, dtype=torch.float64)\n",
      "hess: tensor(0.7456)\n",
      "grad: tensor(0.0030, dtype=torch.float64)\n",
      "hess: tensor(0.1277)\n",
      "grad: tensor(0.0052, dtype=torch.float64)\n",
      "hess: tensor(0.2141)\n",
      "grad: tensor(0.0304, dtype=torch.float64)\n",
      "hess: tensor(0.5102)\n",
      "grad: tensor(0.0752, dtype=torch.float64)\n",
      "hess: tensor(2.1681)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000119\n",
      "grad: tensor(0.0070, dtype=torch.float64)\n",
      "hess: tensor(0.2539)\n",
      "grad: tensor(0.0127, dtype=torch.float64)\n",
      "hess: tensor(0.4457)\n",
      "grad: tensor(0.8539, dtype=torch.float64)\n",
      "hess: tensor(24.0443)\n",
      "grad: tensor(1.5146, dtype=torch.float64)\n",
      "hess: tensor(38.5896)\n",
      "grad: tensor(3.5892, dtype=torch.float64)\n",
      "hess: tensor(78.8178)\n",
      "grad: tensor(1.5484, dtype=torch.float64)\n",
      "hess: tensor(34.8727)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442e254f44b34f57b88b643ac3846c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.6194e-07, dtype=torch.float64)\n",
      "hess: tensor(1.6764e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.2079, dtype=torch.float64)\n",
      "hess: tensor(28.6409)\n",
      "grad: tensor(2.4699, dtype=torch.float64)\n",
      "hess: tensor(61.6703)\n",
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0107)\n",
      "grad: tensor(0.0004, dtype=torch.float64)\n",
      "hess: tensor(0.0123)\n",
      "grad: tensor(1.0573, dtype=torch.float64)\n",
      "hess: tensor(25.6248)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000107\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0430)\n",
      "grad: tensor(1.9531, dtype=torch.float64)\n",
      "hess: tensor(57.7162)\n",
      "grad: tensor(0.9395, dtype=torch.float64)\n",
      "hess: tensor(23.0558)\n",
      "grad: tensor(0.5928, dtype=torch.float64)\n",
      "hess: tensor(16.9878)\n",
      "grad: tensor(0.0042, dtype=torch.float64)\n",
      "hess: tensor(0.1582)\n",
      "grad: tensor(0.0192, dtype=torch.float64)\n",
      "hess: tensor(0.5063)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4644d631997489099ad312889c5f3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.3928e-07, dtype=torch.float64)\n",
      "hess: tensor(1.4017e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.1210, dtype=torch.float64)\n",
      "hess: tensor(27.0338)\n",
      "grad: tensor(2.3509, dtype=torch.float64)\n",
      "hess: tensor(59.8981)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0101)\n",
      "grad: tensor(0.0004, dtype=torch.float64)\n",
      "hess: tensor(0.0112)\n",
      "grad: tensor(1.0080, dtype=torch.float64)\n",
      "hess: tensor(24.7669)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000097\n",
      "grad: tensor(0.0009, dtype=torch.float64)\n",
      "hess: tensor(0.0420)\n",
      "grad: tensor(1.9077, dtype=torch.float64)\n",
      "hess: tensor(56.8312)\n",
      "grad: tensor(0.8491, dtype=torch.float64)\n",
      "hess: tensor(21.1828)\n",
      "grad: tensor(0.5715, dtype=torch.float64)\n",
      "hess: tensor(16.5629)\n",
      "grad: tensor(0.0039, dtype=torch.float64)\n",
      "hess: tensor(0.1458)\n",
      "grad: tensor(0.0178, dtype=torch.float64)\n",
      "hess: tensor(0.4719)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95834c1dc0b6445a978f189883a892a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.0651e-07, dtype=torch.float64)\n",
      "hess: tensor(1.2163e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.0719, dtype=torch.float64)\n",
      "hess: tensor(26.1889)\n",
      "grad: tensor(2.2661, dtype=torch.float64)\n",
      "hess: tensor(58.6791)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0094)\n",
      "grad: tensor(0.0004, dtype=torch.float64)\n",
      "hess: tensor(0.0106)\n",
      "grad: tensor(0.9544, dtype=torch.float64)\n",
      "hess: tensor(23.7746)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000087\n",
      "grad: tensor(0.0009, dtype=torch.float64)\n",
      "hess: tensor(0.0398)\n",
      "grad: tensor(1.8886, dtype=torch.float64)\n",
      "hess: tensor(53.9405)\n",
      "grad: tensor(0.8470, dtype=torch.float64)\n",
      "hess: tensor(27.7757)\n",
      "grad: tensor(0.5793, dtype=torch.float64)\n",
      "hess: tensor(16.9323)\n",
      "grad: tensor(0.0036, dtype=torch.float64)\n",
      "hess: tensor(0.1359)\n",
      "grad: tensor(0.0171, dtype=torch.float64)\n",
      "hess: tensor(0.4573)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184e0971c5d348ddac3b838cc685b99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.7385e-07, dtype=torch.float64)\n",
      "hess: tensor(1.0264e-05)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.0161, dtype=torch.float64)\n",
      "hess: tensor(25.1697)\n",
      "grad: tensor(2.1775, dtype=torch.float64)\n",
      "hess: tensor(57.3273)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0092)\n",
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0096)\n",
      "grad: tensor(0.9092, dtype=torch.float64)\n",
      "hess: tensor(22.9311)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000079\n",
      "grad: tensor(0.0009, dtype=torch.float64)\n",
      "hess: tensor(0.0388)\n",
      "grad: tensor(1.8406, dtype=torch.float64)\n",
      "hess: tensor(52.9970)\n",
      "grad: tensor(0.7842, dtype=torch.float64)\n",
      "hess: tensor(26.1357)\n",
      "grad: tensor(0.5526, dtype=torch.float64)\n",
      "hess: tensor(16.3319)\n",
      "grad: tensor(0.0032, dtype=torch.float64)\n",
      "hess: tensor(0.1236)\n",
      "grad: tensor(0.0160, dtype=torch.float64)\n",
      "hess: tensor(0.4295)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45541b5827854530a036ca372d933178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.5229e-07, dtype=torch.float64)\n",
      "hess: tensor(8.9994e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.9736, dtype=torch.float64)\n",
      "hess: tensor(24.3984)\n",
      "grad: tensor(2.0473, dtype=torch.float64)\n",
      "hess: tensor(55.0465)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0087)\n",
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0088)\n",
      "grad: tensor(0.8496, dtype=torch.float64)\n",
      "hess: tensor(21.7205)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000072\n",
      "grad: tensor(0.0008, dtype=torch.float64)\n",
      "hess: tensor(0.0382)\n",
      "grad: tensor(1.6481, dtype=torch.float64)\n",
      "hess: tensor(51.1099)\n",
      "grad: tensor(0.7736, dtype=torch.float64)\n",
      "hess: tensor(26.0130)\n",
      "grad: tensor(0.5646, dtype=torch.float64)\n",
      "hess: tensor(16.8039)\n",
      "grad: tensor(0.0032, dtype=torch.float64)\n",
      "hess: tensor(0.1215)\n",
      "grad: tensor(0.0158, dtype=torch.float64)\n",
      "hess: tensor(0.4258)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438698d76eb14fdda92ac09d55d65add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.3005e-07, dtype=torch.float64)\n",
      "hess: tensor(7.7133e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.9286, dtype=torch.float64)\n",
      "hess: tensor(23.5514)\n",
      "grad: tensor(1.9679, dtype=torch.float64)\n",
      "hess: tensor(53.7299)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0082)\n",
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0082)\n",
      "grad: tensor(0.8262, dtype=torch.float64)\n",
      "hess: tensor(21.3301)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000066\n",
      "grad: tensor(0.0008, dtype=torch.float64)\n",
      "hess: tensor(0.0375)\n",
      "grad: tensor(1.7196, dtype=torch.float64)\n",
      "hess: tensor(50.4551)\n",
      "grad: tensor(0.7489, dtype=torch.float64)\n",
      "hess: tensor(25.4592)\n",
      "grad: tensor(0.5511, dtype=torch.float64)\n",
      "hess: tensor(16.5518)\n",
      "grad: tensor(0.0029, dtype=torch.float64)\n",
      "hess: tensor(0.1103)\n",
      "grad: tensor(0.0151, dtype=torch.float64)\n",
      "hess: tensor(0.4089)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cb40f67292466fbcda76ab36fa4a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.1461e-07, dtype=torch.float64)\n",
      "hess: tensor(6.8269e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.8799, dtype=torch.float64)\n",
      "hess: tensor(22.5745)\n",
      "grad: tensor(1.8608, dtype=torch.float64)\n",
      "hess: tensor(51.7513)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0077)\n",
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0078)\n",
      "grad: tensor(0.7846, dtype=torch.float64)\n",
      "hess: tensor(20.4796)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000060\n",
      "grad: tensor(0.0008, dtype=torch.float64)\n",
      "hess: tensor(0.0364)\n",
      "grad: tensor(1.5599, dtype=torch.float64)\n",
      "hess: tensor(49.2071)\n",
      "grad: tensor(0.6921, dtype=torch.float64)\n",
      "hess: tensor(23.8366)\n",
      "grad: tensor(0.5519, dtype=torch.float64)\n",
      "hess: tensor(16.6972)\n",
      "grad: tensor(0.0028, dtype=torch.float64)\n",
      "hess: tensor(0.1067)\n",
      "grad: tensor(0.0141, dtype=torch.float64)\n",
      "hess: tensor(0.3860)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55385dedafd9403d848af888280cf070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(9.8757e-08, dtype=torch.float64)\n",
      "hess: tensor(5.9070e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.8401, dtype=torch.float64)\n",
      "hess: tensor(21.7931)\n",
      "grad: tensor(1.8732, dtype=torch.float64)\n",
      "hess: tensor(52.3226)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0074)\n",
      "grad: tensor(0.0003, dtype=torch.float64)\n",
      "hess: tensor(0.0072)\n",
      "grad: tensor(0.7371, dtype=torch.float64)\n",
      "hess: tensor(19.4635)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000055\n",
      "grad: tensor(0.0008, dtype=torch.float64)\n",
      "hess: tensor(0.0347)\n",
      "grad: tensor(1.5698, dtype=torch.float64)\n",
      "hess: tensor(47.2127)\n",
      "grad: tensor(0.6321, dtype=torch.float64)\n",
      "hess: tensor(22.0843)\n",
      "grad: tensor(0.5441, dtype=torch.float64)\n",
      "hess: tensor(16.5930)\n",
      "grad: tensor(0.0025, dtype=torch.float64)\n",
      "hess: tensor(0.0980)\n",
      "grad: tensor(0.0132, dtype=torch.float64)\n",
      "hess: tensor(0.3621)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d3f7f35d4c47f08a7d3312cc170c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(9.0481e-08, dtype=torch.float64)\n",
      "hess: tensor(5.4335e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.8035, dtype=torch.float64)\n",
      "hess: tensor(21.0551)\n",
      "grad: tensor(1.8031, dtype=torch.float64)\n",
      "hess: tensor(51.0631)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0069)\n",
      "grad: tensor(0.0002, dtype=torch.float64)\n",
      "hess: tensor(0.0069)\n",
      "grad: tensor(0.0203, dtype=torch.float64)\n",
      "hess: tensor(0.3564)\n",
      "grad: tensor(0.0016, dtype=torch.float64)\n",
      "hess: tensor(0.0493)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000052\n",
      "grad: tensor(0.1633, dtype=torch.float64)\n",
      "hess: tensor(6.5456)\n",
      "grad: tensor(0.0423, dtype=torch.float64)\n",
      "hess: tensor(1.5572)\n",
      "grad: tensor(1.0591, dtype=torch.float64)\n",
      "hess: tensor(30.1710)\n",
      "grad: tensor(0.0023, dtype=torch.float64)\n",
      "hess: tensor(0.0910)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2346b4b1ad494b9f6a2cfe6557e7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(7.7600e-08, dtype=torch.float64)\n",
      "hess: tensor(4.6790e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(2.0476, dtype=torch.float64)\n",
      "hess: tensor(54.3258)\n",
      "grad: tensor(9.6674e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0004)\n",
      "grad: tensor(0.0001, dtype=torch.float64)\n",
      "hess: tensor(0.0047)\n",
      "grad: tensor(0.0193, dtype=torch.float64)\n",
      "hess: tensor(0.3370)\n",
      "grad: tensor(0.0015, dtype=torch.float64)\n",
      "hess: tensor(0.0467)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000048\n",
      "grad: tensor(0.1538, dtype=torch.float64)\n",
      "hess: tensor(6.1976)\n",
      "grad: tensor(0.0417, dtype=torch.float64)\n",
      "hess: tensor(1.5451)\n",
      "grad: tensor(1.0426, dtype=torch.float64)\n",
      "hess: tensor(29.9202)\n",
      "grad: tensor(0.0022, dtype=torch.float64)\n",
      "hess: tensor(0.0872)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829dcda4f1fc4534a6182e7633b08f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(6.9753e-08, dtype=torch.float64)\n",
      "hess: tensor(4.2216e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(2.0090, dtype=torch.float64)\n",
      "hess: tensor(53.8166)\n",
      "grad: tensor(9.3021e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0004)\n",
      "grad: tensor(9.6699e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0043)\n",
      "grad: tensor(0.0185, dtype=torch.float64)\n",
      "hess: tensor(0.3242)\n",
      "grad: tensor(0.0014, dtype=torch.float64)\n",
      "hess: tensor(0.0430)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000044\n",
      "grad: tensor(0.1458, dtype=torch.float64)\n",
      "hess: tensor(5.9122)\n",
      "grad: tensor(0.0408, dtype=torch.float64)\n",
      "hess: tensor(1.5205)\n",
      "grad: tensor(0.9992, dtype=torch.float64)\n",
      "hess: tensor(28.9793)\n",
      "grad: tensor(0.0021, dtype=torch.float64)\n",
      "hess: tensor(0.0810)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b87dd615234b3089914bcad1725194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(6.1429e-08, dtype=torch.float64)\n",
      "hess: tensor(3.7311e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9974, dtype=torch.float64)\n",
      "hess: tensor(53.8843)\n",
      "grad: tensor(6.2239e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0003)\n",
      "grad: tensor(9.2280e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0042)\n",
      "grad: tensor(0.0178, dtype=torch.float64)\n",
      "hess: tensor(0.3135)\n",
      "grad: tensor(0.0013, dtype=torch.float64)\n",
      "hess: tensor(0.0408)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000041\n",
      "grad: tensor(0.1409, dtype=torch.float64)\n",
      "hess: tensor(5.7419)\n",
      "grad: tensor(0.0383, dtype=torch.float64)\n",
      "hess: tensor(1.4334)\n",
      "grad: tensor(0.9772, dtype=torch.float64)\n",
      "hess: tensor(28.5642)\n",
      "grad: tensor(0.0019, dtype=torch.float64)\n",
      "hess: tensor(0.0749)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a193460c4fc140efb40f40856db56b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(5.5369e-08, dtype=torch.float64)\n",
      "hess: tensor(3.3752e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9510, dtype=torch.float64)\n",
      "hess: tensor(53.1335)\n",
      "grad: tensor(5.9149e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0003)\n",
      "grad: tensor(8.6312e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0039)\n",
      "grad: tensor(0.0171, dtype=torch.float64)\n",
      "hess: tensor(0.3017)\n",
      "grad: tensor(0.0012, dtype=torch.float64)\n",
      "hess: tensor(0.0384)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000038\n",
      "grad: tensor(0.1323, dtype=torch.float64)\n",
      "hess: tensor(5.4184)\n",
      "grad: tensor(0.0373, dtype=torch.float64)\n",
      "hess: tensor(1.4008)\n",
      "grad: tensor(0.9363, dtype=torch.float64)\n",
      "hess: tensor(27.6405)\n",
      "grad: tensor(0.0018, dtype=torch.float64)\n",
      "hess: tensor(0.0710)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a160ccab424a0192a83c53f71b7704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(4.6800e-08, dtype=torch.float64)\n",
      "hess: tensor(2.8627e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9612, dtype=torch.float64)\n",
      "hess: tensor(53.5984)\n",
      "grad: tensor(5.6632e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0003)\n",
      "grad: tensor(7.8476e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0036)\n",
      "grad: tensor(0.0164, dtype=torch.float64)\n",
      "hess: tensor(0.2911)\n",
      "grad: tensor(0.0011, dtype=torch.float64)\n",
      "hess: tensor(0.0363)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000036\n",
      "grad: tensor(0.1251, dtype=torch.float64)\n",
      "hess: tensor(5.1491)\n",
      "grad: tensor(0.0355, dtype=torch.float64)\n",
      "hess: tensor(1.3396)\n",
      "grad: tensor(0.8926, dtype=torch.float64)\n",
      "hess: tensor(26.6223)\n",
      "grad: tensor(0.0017, dtype=torch.float64)\n",
      "hess: tensor(0.0665)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093d12e9e2f94e71b0ec3c2ba7b4ead7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(4.2548e-08, dtype=torch.float64)\n",
      "hess: tensor(2.6115e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9627, dtype=torch.float64)\n",
      "hess: tensor(53.9072)\n",
      "grad: tensor(5.3625e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "grad: tensor(7.5313e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0034)\n",
      "grad: tensor(0.0158, dtype=torch.float64)\n",
      "hess: tensor(0.2814)\n",
      "grad: tensor(0.0011, dtype=torch.float64)\n",
      "hess: tensor(0.0344)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000034\n",
      "grad: tensor(0.1208, dtype=torch.float64)\n",
      "hess: tensor(4.9917)\n",
      "grad: tensor(0.0356, dtype=torch.float64)\n",
      "hess: tensor(1.3503)\n",
      "grad: tensor(0.9173, dtype=torch.float64)\n",
      "hess: tensor(27.4039)\n",
      "grad: tensor(0.0016, dtype=torch.float64)\n",
      "hess: tensor(0.0621)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd6af03eba540f88d45ccbf06127bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(3.7257e-08, dtype=torch.float64)\n",
      "hess: tensor(2.2943e-06)\n",
      "\taccuracy:90.234375\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9437, dtype=torch.float64)\n",
      "hess: tensor(53.7163)\n",
      "grad: tensor(5.1471e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "grad: tensor(7.3439e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0033)\n",
      "grad: tensor(0.0151, dtype=torch.float64)\n",
      "hess: tensor(0.2714)\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0327)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000032\n",
      "grad: tensor(0.1139, dtype=torch.float64)\n",
      "hess: tensor(4.7269)\n",
      "grad: tensor(0.0327, dtype=torch.float64)\n",
      "hess: tensor(1.2475)\n",
      "grad: tensor(0.8736, dtype=torch.float64)\n",
      "hess: tensor(26.3597)\n",
      "grad: tensor(0.0015, dtype=torch.float64)\n",
      "hess: tensor(0.0581)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c78391995824078916a302ec26707cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(3.3076e-08, dtype=torch.float64)\n",
      "hess: tensor(2.0434e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9410, dtype=torch.float64)\n",
      "hess: tensor(53.8969)\n",
      "grad: tensor(4.9828e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "grad: tensor(6.4146e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0030)\n",
      "grad: tensor(0.0146, dtype=torch.float64)\n",
      "hess: tensor(0.2622)\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0310)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000030\n",
      "grad: tensor(0.1091, dtype=torch.float64)\n",
      "hess: tensor(4.5496)\n",
      "grad: tensor(0.0315, dtype=torch.float64)\n",
      "hess: tensor(1.2069)\n",
      "grad: tensor(0.8302, dtype=torch.float64)\n",
      "hess: tensor(25.2943)\n",
      "grad: tensor(0.0014, dtype=torch.float64)\n",
      "hess: tensor(0.0555)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9529d00e34784e4fb568796603e044b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.8865e-08, dtype=torch.float64)\n",
      "hess: tensor(1.7888e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9271, dtype=torch.float64)\n",
      "hess: tensor(53.8060)\n",
      "grad: tensor(4.8667e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "grad: tensor(5.9089e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0028)\n",
      "grad: tensor(0.0140, dtype=torch.float64)\n",
      "hess: tensor(0.2522)\n",
      "grad: tensor(0.0009, dtype=torch.float64)\n",
      "hess: tensor(0.0296)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000028\n",
      "grad: tensor(0.1033, dtype=torch.float64)\n",
      "hess: tensor(4.3266)\n",
      "grad: tensor(0.0304, dtype=torch.float64)\n",
      "hess: tensor(1.1704)\n",
      "grad: tensor(0.8250, dtype=torch.float64)\n",
      "hess: tensor(25.2613)\n",
      "grad: tensor(0.0013, dtype=torch.float64)\n",
      "hess: tensor(0.0527)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8137260ffad240e0b80caae828cce383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.5671e-08, dtype=torch.float64)\n",
      "hess: tensor(1.5956e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(1.9206, dtype=torch.float64)\n",
      "hess: tensor(53.8873)\n",
      "grad: tensor(4.7188e-06, dtype=torch.float64)\n",
      "hess: tensor(0.0002)\n",
      "grad: tensor(5.4868e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0026)\n",
      "grad: tensor(0.0015, dtype=torch.float64)\n",
      "hess: tensor(0.0499)\n",
      "grad: tensor(0.0014, dtype=torch.float64)\n",
      "hess: tensor(0.0646)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000026\n",
      "grad: tensor(2.0543, dtype=torch.float64)\n",
      "hess: tensor(45.1217)\n",
      "grad: tensor(0.0085, dtype=torch.float64)\n",
      "hess: tensor(0.4420)\n",
      "grad: tensor(0.1599, dtype=torch.float64)\n",
      "hess: tensor(7.4889)\n",
      "grad: tensor(2.8254, dtype=torch.float64)\n",
      "hess: tensor(73.7460)\n",
      "grad: tensor(0.0081, dtype=torch.float64)\n",
      "hess: tensor(0.2312)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa2f4f0e08e41f6ad3fdd0ac115aaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.2614e-08, dtype=torch.float64)\n",
      "hess: tensor(1.4098e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.7793e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0023)\n",
      "grad: tensor(7.4860, dtype=torch.float64)\n",
      "hess: tensor(124.7300)\n",
      "grad: tensor(0.0015, dtype=torch.float64)\n",
      "hess: tensor(0.0492)\n",
      "grad: tensor(0.0013, dtype=torch.float64)\n",
      "hess: tensor(0.0604)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000025\n",
      "grad: tensor(2.0227, dtype=torch.float64)\n",
      "hess: tensor(44.7823)\n",
      "grad: tensor(0.0081, dtype=torch.float64)\n",
      "hess: tensor(0.4243)\n",
      "grad: tensor(0.1585, dtype=torch.float64)\n",
      "hess: tensor(7.4443)\n",
      "grad: tensor(2.8474, dtype=torch.float64)\n",
      "hess: tensor(74.3806)\n",
      "grad: tensor(0.0078, dtype=torch.float64)\n",
      "hess: tensor(0.2234)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ba2e46498248488c784bf65d2cc03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(2.0660e-08, dtype=torch.float64)\n",
      "hess: tensor(1.2913e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(5.3327e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0021)\n",
      "grad: tensor(7.3674, dtype=torch.float64)\n",
      "hess: tensor(124.2744)\n",
      "grad: tensor(0.0014, dtype=torch.float64)\n",
      "hess: tensor(0.0446)\n",
      "grad: tensor(0.0012, dtype=torch.float64)\n",
      "hess: tensor(0.0553)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000024\n",
      "grad: tensor(1.9813, dtype=torch.float64)\n",
      "hess: tensor(44.2514)\n",
      "grad: tensor(0.0079, dtype=torch.float64)\n",
      "hess: tensor(0.4112)\n",
      "grad: tensor(0.1592, dtype=torch.float64)\n",
      "hess: tensor(7.5251)\n",
      "grad: tensor(2.6425, dtype=torch.float64)\n",
      "hess: tensor(70.8877)\n",
      "grad: tensor(0.0075, dtype=torch.float64)\n",
      "hess: tensor(0.2169)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cea804567fd46f99a8afaa4224a0e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.7951e-08, dtype=torch.float64)\n",
      "hess: tensor(1.1252e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(4.8991e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0019)\n",
      "grad: tensor(7.1017, dtype=torch.float64)\n",
      "hess: tensor(123.0506)\n",
      "grad: tensor(0.0013, dtype=torch.float64)\n",
      "hess: tensor(0.0420)\n",
      "grad: tensor(0.0011, dtype=torch.float64)\n",
      "hess: tensor(0.0519)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000023\n",
      "grad: tensor(1.9458, dtype=torch.float64)\n",
      "hess: tensor(43.8184)\n",
      "grad: tensor(0.0075, dtype=torch.float64)\n",
      "hess: tensor(0.3941)\n",
      "grad: tensor(0.1444, dtype=torch.float64)\n",
      "hess: tensor(6.8602)\n",
      "grad: tensor(2.6958, dtype=torch.float64)\n",
      "hess: tensor(72.1265)\n",
      "grad: tensor(0.0071, dtype=torch.float64)\n",
      "hess: tensor(0.2051)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7af362377c9429c8d19ac1bac7aa096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.6481e-08, dtype=torch.float64)\n",
      "hess: tensor(1.0359e-06)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(4.4640e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0018)\n",
      "grad: tensor(6.9666, dtype=torch.float64)\n",
      "hess: tensor(122.4483)\n",
      "grad: tensor(0.0012, dtype=torch.float64)\n",
      "hess: tensor(0.0395)\n",
      "grad: tensor(0.0011, dtype=torch.float64)\n",
      "hess: tensor(0.0483)\n",
      "\taccuracy:91.015625\n",
      "\tloss: 0.000021\n",
      "grad: tensor(1.9135, dtype=torch.float64)\n",
      "hess: tensor(43.4242)\n",
      "grad: tensor(0.0072, dtype=torch.float64)\n",
      "hess: tensor(0.3792)\n",
      "grad: tensor(0.1470, dtype=torch.float64)\n",
      "hess: tensor(7.0137)\n",
      "grad: tensor(2.5890, dtype=torch.float64)\n",
      "hess: tensor(70.3464)\n",
      "grad: tensor(0.0068, dtype=torch.float64)\n",
      "hess: tensor(0.1970)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9929ec55e804ac98e3a780446e40c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.4139e-08, dtype=torch.float64)\n",
      "hess: tensor(8.9112e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(3.7900e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0015)\n",
      "grad: tensor(6.7513, dtype=torch.float64)\n",
      "hess: tensor(121.3553)\n",
      "grad: tensor(0.0011, dtype=torch.float64)\n",
      "hess: tensor(0.0376)\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0457)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000020\n",
      "grad: tensor(1.8803, dtype=torch.float64)\n",
      "hess: tensor(43.0088)\n",
      "grad: tensor(0.0069, dtype=torch.float64)\n",
      "hess: tensor(0.3626)\n",
      "grad: tensor(0.1403, dtype=torch.float64)\n",
      "hess: tensor(6.7250)\n",
      "grad: tensor(2.6447, dtype=torch.float64)\n",
      "hess: tensor(71.6252)\n",
      "grad: tensor(0.0065, dtype=torch.float64)\n",
      "hess: tensor(0.1898)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4cc9f615ef47f086d4de5bef10c0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.3269e-08, dtype=torch.float64)\n",
      "hess: tensor(8.3832e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "hess: tensor(120.9443)\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0335)\n",
      "grad: tensor(0.0009, dtype=torch.float64)\n",
      "hess: tensor(0.0397)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000018\n",
      "grad: tensor(1.8178, dtype=torch.float64)\n",
      "hess: tensor(42.1986)\n",
      "grad: tensor(0.0066, dtype=torch.float64)\n",
      "hess: tensor(0.3487)\n",
      "grad: tensor(0.1238, dtype=torch.float64)\n",
      "hess: tensor(5.9824)\n",
      "grad: tensor(2.5001, dtype=torch.float64)\n",
      "hess: tensor(69.2721)\n",
      "grad: tensor(0.0059, dtype=torch.float64)\n",
      "hess: tensor(0.1727)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d45b100dbf04c13a20c91e4771d33d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(1.0511e-08, dtype=torch.float64)\n",
      "hess: tensor(6.6741e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(3.3411e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0013)\n",
      "grad: tensor(6.3578, dtype=torch.float64)\n",
      "hess: tensor(119.3409)\n",
      "grad: tensor(0.0010, dtype=torch.float64)\n",
      "hess: tensor(0.0332)\n",
      "grad: tensor(0.0008, dtype=torch.float64)\n",
      "hess: tensor(0.0373)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000018\n",
      "grad: tensor(1.7968, dtype=torch.float64)\n",
      "hess: tensor(41.9797)\n",
      "grad: tensor(0.0064, dtype=torch.float64)\n",
      "hess: tensor(0.3408)\n",
      "grad: tensor(0.1261, dtype=torch.float64)\n",
      "hess: tensor(6.1236)\n",
      "grad: tensor(2.4772, dtype=torch.float64)\n",
      "hess: tensor(69.0255)\n",
      "grad: tensor(0.0057, dtype=torch.float64)\n",
      "hess: tensor(0.1670)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01a7b2a267f46d0a1216af7f91ab98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(9.2750e-09, dtype=torch.float64)\n",
      "hess: tensor(5.9034e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(3.2472e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0012)\n",
      "grad: tensor(6.2692, dtype=torch.float64)\n",
      "hess: tensor(118.8811)\n",
      "grad: tensor(0.0009, dtype=torch.float64)\n",
      "hess: tensor(0.0300)\n",
      "grad: tensor(0.0007, dtype=torch.float64)\n",
      "hess: tensor(0.0349)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000017\n",
      "grad: tensor(1.7644, dtype=torch.float64)\n",
      "hess: tensor(41.5236)\n",
      "grad: tensor(0.0061, dtype=torch.float64)\n",
      "hess: tensor(0.3243)\n",
      "grad: tensor(0.1162, dtype=torch.float64)\n",
      "hess: tensor(5.6633)\n",
      "grad: tensor(2.4163, dtype=torch.float64)\n",
      "hess: tensor(68.0105)\n",
      "grad: tensor(0.0054, dtype=torch.float64)\n",
      "hess: tensor(0.1587)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276401ebc8464012a9e691aeb6822278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(8.4059e-09, dtype=torch.float64)\n",
      "hess: tensor(5.3629e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(2.5943e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0011)\n",
      "grad: tensor(5.9921, dtype=torch.float64)\n",
      "hess: tensor(117.0862)\n",
      "grad: tensor(0.0024, dtype=torch.float64)\n",
      "hess: tensor(0.1125)\n",
      "grad: tensor(8.6440e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0027)\n",
      "grad: tensor(0.0229, dtype=torch.float64)\n",
      "hess: tensor(0.7327)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000016\n",
      "grad: tensor(0.0641, dtype=torch.float64)\n",
      "hess: tensor(2.7968)\n",
      "grad: tensor(0.1868, dtype=torch.float64)\n",
      "hess: tensor(6.5929)\n",
      "grad: tensor(0.3645, dtype=torch.float64)\n",
      "hess: tensor(14.3366)\n",
      "grad: tensor(0.4484, dtype=torch.float64)\n",
      "hess: tensor(12.9771)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7092ac5a2de4bc5ad902fba109f1dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(7.4177e-09, dtype=torch.float64)\n",
      "hess: tensor(4.7438e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0774, dtype=torch.float64)\n",
      "hess: tensor(2.6464)\n",
      "grad: tensor(0.0023, dtype=torch.float64)\n",
      "hess: tensor(0.1099)\n",
      "grad: tensor(8.3308e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0026)\n",
      "grad: tensor(0.0220, dtype=torch.float64)\n",
      "hess: tensor(0.7077)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000015\n",
      "grad: tensor(0.0612, dtype=torch.float64)\n",
      "hess: tensor(2.6800)\n",
      "grad: tensor(0.1951, dtype=torch.float64)\n",
      "hess: tensor(6.9013)\n",
      "grad: tensor(0.3775, dtype=torch.float64)\n",
      "hess: tensor(14.8908)\n",
      "grad: tensor(0.4289, dtype=torch.float64)\n",
      "hess: tensor(12.4675)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8025e7f450495a97834fdfb22325e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: tensor(6.8866e-09, dtype=torch.float64)\n",
      "hess: tensor(4.4142e-07)\n",
      "\taccuracy:90.625\n",
      "\tloss: 0.000000\n",
      "grad: tensor(0.0755, dtype=torch.float64)\n",
      "hess: tensor(2.5933)\n",
      "grad: tensor(0.0023, dtype=torch.float64)\n",
      "hess: tensor(0.1104)\n",
      "grad: tensor(7.7660e-05, dtype=torch.float64)\n",
      "hess: tensor(0.0024)\n",
      "grad: tensor(0.0215, dtype=torch.float64)\n",
      "hess: tensor(0.6921)\n",
      "\taccuracy:91.40625\n",
      "\tloss: 0.000015\n",
      "grad: tensor(0.0586, dtype=torch.float64)\n",
      "hess: tensor(2.5735)\n",
      "grad: tensor(0.1893, dtype=torch.float64)\n",
      "hess: tensor(6.7239)\n",
      "grad: tensor(0.3749, dtype=torch.float64)\n",
      "hess: tensor(14.8610)\n",
      "grad: tensor(0.4219, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 397>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    393\u001b[0m         grad_list\u001b[38;5;241m.\u001b[39mappend(train_model\u001b[38;5;241m.\u001b[39mgrads_norms)\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_list, hess_norm_list\n\u001b[0;32m--> 397\u001b[0m grad_list, hess_norm_list \u001b[38;5;241m=\u001b[39m \u001b[43mexp_get_lp_sm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m              \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg_times\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult_root_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_reduce_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreq_reduce_by\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfreq_reduce_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreq_reduce_after\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mexp_get_lp_sm\u001b[0;34m(train_data_all, test_data_all, op_features, weight, times, epochs, root_dir, path, clear_file, freq_reduce_by, freq_reduce_after)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    384\u001b[0m train_model \u001b[38;5;241m=\u001b[39m Train_nn(\u001b[38;5;241m784\u001b[39m, weight, op_features, lr\u001b[38;5;241m=\u001b[39m details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha_0\u001b[39m\u001b[38;5;124m'\u001b[39m], decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 385\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_grads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_hessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbook_keep_freq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mstore_gen_err\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_pt_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_reduce_by\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfreq_reduce_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_reduce_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_reduce_after\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(grad_file_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    388\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(grad) \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m train_model\u001b[38;5;241m.\u001b[39mgrads_norms]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTrain_nn.fit\u001b[0;34m(self, train_loader, test_loader, epochs, store_grads, store_hessian, store_gen_err, store_weights, store_pt_loss, store_freq, freq_reduce_by, freq_reduce_after)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store_hessian \u001b[38;5;129;01mand\u001b[39;00m (batch\u001b[38;5;241m%\u001b[39m store_freq\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m#assert False, \"Not implemented\"\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 321\u001b[0m     hess_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_hessianv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhess:\u001b[39m\u001b[38;5;124m'\u001b[39m,hess_val)\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhess_norms\u001b[38;5;241m.\u001b[39mappend(hess_val)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTrain_nn.get_hessianv2\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    250\u001b[0m     local_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(out, y)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m local_loss\n\u001b[0;32m--> 252\u001b[0m hess_mat \u001b[38;5;241m=\u001b[39m \u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fun_hess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# print(f'len of hess mat:{len(hess_mat)}')\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# print(f'hess_mat[0] shape:{len(hess_mat[0])}')\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# print(f'hess_mat[0][0] shape:{hess_mat[0][0].shape}')\u001b[39;00m\n\u001b[1;32m    256\u001b[0m hess_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:808\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[1;32m    805\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[0;32m--> 808\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:670\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    668\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 670\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd.functional import hessian\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "from torch.nn.utils import _stateless\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "# device\n",
    "\n",
    "details = {}\n",
    "details['use_db'] = 'mnist'\n",
    "details['result_root_dir']='results/t0/'\n",
    "details['result_path']='try1_t8_w16'\n",
    "details['g_weight'] = [16]\n",
    "# details['ratio'] = 15\n",
    "details['book_keep_freq'] = 20\n",
    "details['g_times'] = 8\n",
    "details['g_epochs'] = 10000\n",
    "details['alpha_0']= 0.003\n",
    "details['freq_reduce_by'] = 20\n",
    "details['freq_reduce_after'] = 100\n",
    "\n",
    "details['training_step_limit'] = 2000000 ## this is to train for max updates per epochs\n",
    "details['stop_hess_computation'] = 1000000 ## Stop computing hessian after calculated these many times\n",
    "\n",
    "\n",
    "print(f'selected weight:{details[\"g_weight\"]}')\n",
    "\n",
    "with open(details['result_root_dir']+'details_'+details['result_path']+'.txt', 'w+') as f:\n",
    "    for key, val in details.items():\n",
    "        content = key + ' : '+str(val) + '\\n'\n",
    "        f.write(content)\n",
    "        \n",
    "torch.manual_seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\"\n",
    "\n",
    "train_data_all = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data_all = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "# print(f'train data:{train_data}')\n",
    "# print(f'test data:{test_data}')\n",
    "\n",
    "def get_random_subset(train_data_all, test_data_all):    \n",
    "    # train_indices = torch.arange(20000)\n",
    "    test_indices = torch.arange(256)\n",
    "    train_indices = torch.randint(60000-1, (2000,))\n",
    "    # print(f'train indices:{train_indices[:10]}')\n",
    "    train_data = data_utils.Subset(train_data_all, train_indices)\n",
    "    test_data = data_utils.Subset(test_data_all, test_indices)\n",
    "    # print(f'train data:{train_data}')\n",
    "    # print(f'test data:{test_data}')\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(0)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=256,\n",
    "        num_workers=num_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "    )\n",
    "    print(f'train data size:{len(train_loader.dataset)}')\n",
    "    print(f'test data size:{len(test_loader.dataset)}')\n",
    "    # X_mat, y_mat = torch.Tensor(len(train_loader.dataset),784), torch.Tensor(len(train_loader.dataset)).long()\n",
    "    # for i, (data, label) in enumerate(train_loader):\n",
    "    #     X_mat[i] = data.flatten()\n",
    "    #     y_mat[i] = label.flatten()\n",
    "    # print(f'X_mat shape:{X_mat.shape}, y_mat shape:{y_mat.shape}')\n",
    "    return train_loader, test_loader #, X_mat, y_mat\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, hidden_layers, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = len(hidden_layers) + 1\n",
    "        self.total_params_len = 0\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        prev_weight = input_features\n",
    "        \n",
    "        for i, weight in enumerate(hidden_layers):\n",
    "            self.fc_layers.append(nn.Linear(prev_weight, weight))\n",
    "            self.total_params_len += prev_weight*weight + weight\n",
    "            prev_weight = weight\n",
    "        \n",
    "        self.fc_last = nn.Linear(hidden_layers[-1], output_size)\n",
    "        self.total_params_len += hidden_layers[-1]*output_size + output_size\n",
    "        \n",
    "        ### Others required params\n",
    "        self.param_list = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        # print('x shape in forward',x.shape)\n",
    "        for fc_layer in self.fc_layers:\n",
    "            x = F.relu(fc_layer(x))\n",
    "        x = self.fc_last(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, Y, X_val, Y_val, epochs, batch_size=1, **kwargs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters())\n",
    "        \n",
    "\n",
    "class Train_nn:\n",
    "    \n",
    "    def __init__(self, input_features, hidden_layers, output_size, lr, decay=True):\n",
    "        self.model = Net(input_features, hidden_layers=hidden_layers, output_size=output_size)\n",
    "        self.model.to(device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        if decay:\n",
    "            lr_lambda = lambda it: 1/(it+1)\n",
    "        else:\n",
    "            lr_lambda = lambda it: 1\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda= lr_lambda)\n",
    "        \n",
    "    def get_loss(self, X, y, params=None):\n",
    "        # if params is not None:\n",
    "        assert False, \"Model not initialized with given params\"\n",
    "        op = self.model(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        return loss\n",
    "    \n",
    "    def get_gradient(self):\n",
    "        params = (self.model.parameters())\n",
    "        grad_norm_sq = torch.tensor(0, dtype=float).to(device)\n",
    "        # print('grad Norm init:', grad_norm_sq)\n",
    "        for param in self.model.parameters():\n",
    "            temp = param.grad.data.pow(2).sum()\n",
    "            # print(f'param grad norm \\n\\tsum:{temp.data}')#,\\n\\tshape:{param.shape}')\n",
    "            grad_norm_sq += temp\n",
    "            \n",
    "        return grad_norm_sq.sqrt().cpu()\n",
    "    \n",
    "    def get_gradientv2(self, X, y):\n",
    "        names = list(n for n, _ in self.model.named_parameters())\n",
    "        def loss_fun_grad(*params):\n",
    "            out: torch.Tensor = _stateless.functional_call(self.model, {n: p for n, p in zip(names, params)}, X)\n",
    "            local_loss = self.loss_fn(out, y)\n",
    "            return local_loss\n",
    "        grad_mat = torch.autograd.grad(loss_fun_grad, tuple(self.model.parameters()))\n",
    "        # print(f'len of hess mat:{len(hess_mat)}')\n",
    "        # print(f'hess_mat[0] shape:{len(hess_mat[0])}')\n",
    "        # print(f'hess_mat[0][0] shape:{hess_mat[0][0].shape}')\n",
    "        grad_norm = torch.tensor(0.).to(device)\n",
    "        for i in range(len(grad_mat)):\n",
    "            for j in range(len(grad_mat[0])):\n",
    "                grad_norm+= grad_mat[i][j].pow(2).sum()\n",
    "        grad_norm = grad_norm.sqrt()\n",
    "        # print(f'v2 hess norm{hess_norm}')\n",
    "        return grad_norm.cpu()\n",
    "    \n",
    "    def try_operator_norm(self, hess_mat):\n",
    "        for i in len(hess_mat):\n",
    "            for j in len(hess_mat[0]):\n",
    "                torch.unsqueeze(hess_mat[i][i],0)\n",
    "        hess_tensor_dim = list(hess_mat[0][0].shape)\n",
    "        hess_tensor_dim += [n*2,n*2]\n",
    "        hess_mat_np = np.zeros(shape=hess_tensor_dim)\n",
    "        hess_tensor = torch.tensor(hess_mat_np)\n",
    "        torch.cat(hess_mat, out=hess_tensor)\n",
    "        \n",
    "        hess_mat.reshpe(n*2,n*2)\n",
    "        hess_norm = torch.linalg.norm(hess_mat, 2)\n",
    "        assert False, \"Not working\"\n",
    "    \n",
    "    def get_hessian(self, X, y):\n",
    "        prev_params = copy.deepcopy(list(self.model.parameters()))\n",
    "        n = self.model.layers\n",
    "        def local_model(*params):\n",
    "            # print(f'len of params:{len(params)}')\n",
    "            # print(f'shape of params[0]:{params[0].shape}')\n",
    "            # with torch.no_grad():\n",
    "            #initialize model with given params\n",
    "            i = 0\n",
    "            for i, param in enumerate(self.model.parameters()):\n",
    "                param.data = params[i]\n",
    "            pred = self.model(X)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "            # print(f'loss type:{type(loss)}')\n",
    "            return loss\n",
    "        p =list(self.model.parameters())\n",
    "        hess_mat = hessian(local_model, tuple(p))\n",
    "        hess_norm = torch.tensor(0.).to(device)\n",
    "        for i in range(len(hess_mat)):\n",
    "            for j in range(len(hess_mat[0])):\n",
    "                hess_norm+= hess_mat[i][j].pow(2).sum()\n",
    "        \n",
    "        # print(f'Hess mat len:{len(hess_mat)}')\n",
    "        # print(f'Hess mat[0] len:{len(hess_mat[0])}')\n",
    "        # print(f'Hess mat[0][0] shape:{hess_mat[0][0].shape}')\n",
    "        \n",
    "        hess_norm = hess_norm.sqrt()\n",
    "        # print(f'hess norm:{hess_norm}')\n",
    "        \n",
    "        # Reinitialize the original params to model\n",
    "        for i, param in enumerate(self.model.parameters()):\n",
    "                param.data = prev_params[i]\n",
    "        \n",
    "        return hess_norm\n",
    "    \n",
    "    def get_hessianv2(self, X,y):\n",
    "        names = list(n for n, _ in self.model.named_parameters())\n",
    "        def loss_fun_hess(*params):\n",
    "            out: torch.Tensor = _stateless.functional_call(self.model, {n: p for n, p in zip(names, params)}, X)\n",
    "            local_loss = self.loss_fn(out, y)\n",
    "            return local_loss\n",
    "        hess_mat = hessian(loss_fun_hess, tuple(self.model.parameters()))\n",
    "        # print(f'len of hess mat:{len(hess_mat)}')\n",
    "        # print(f'hess_mat[0] shape:{len(hess_mat[0])}')\n",
    "        # print(f'hess_mat[0][0] shape:{hess_mat[0][0].shape}')\n",
    "        hess_norm = torch.tensor(0.).to(device)\n",
    "        for i in range(len(hess_mat)):\n",
    "            for j in range(len(hess_mat[0])):\n",
    "                hess_norm+= hess_mat[i][j].pow(2).sum()\n",
    "        hess_norm = hess_norm.sqrt()\n",
    "        # print(f'v2 hess norm{hess_norm}')\n",
    "        return hess_norm.cpu()\n",
    "        \n",
    "    def fit(self, train_loader, test_loader, epochs, store_grads=False, store_hessian=False, store_gen_err=False, store_weights=False, store_pt_loss=True, store_freq = 20, freq_reduce_by=None, freq_reduce_after=None):\n",
    "        \n",
    "        ## For Book keeping results ##\n",
    "        self.grads_norms = []\n",
    "        self.grads_normsv2 = []\n",
    "        self.param_list = []\n",
    "        self.hess_norms = []\n",
    "        self.gen_err = []\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.point_loss = []\n",
    "        ## Initializing values ##\n",
    "        terminate_training = False\n",
    "        store_count = 0\n",
    "        \n",
    "        for epoch in tqdm(range(epochs), total=epochs, unit=\"epoch\", disable=True):\n",
    "            if terminate_training == True:\n",
    "                break\n",
    "            for batch, (X, y) in tqdm(enumerate(train_loader), total=len(train_loader), unit='batch'):\n",
    "                if batch>details['training_step_limit']:\n",
    "                    terminate_training = True\n",
    "                    break\n",
    "                \n",
    "                X, y =X.to(device), y.to(device)\n",
    "                pred = self.model(X)\n",
    "                loss = self.loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                ## Saving point loss\n",
    "                if store_pt_loss and (batch%store_freq==0):\n",
    "                    self.point_loss.append(loss.item())\n",
    "                    \n",
    "                ## Saving the weights\n",
    "                if store_weights and (batch%store_freq==0):\n",
    "                    current_params = tuple(self.model.parameters())\n",
    "                    self.param_list.append(current_params)\n",
    "                \n",
    "                ## computing and saving the gradient\n",
    "                if store_grads and (batch% store_freq == 0):\n",
    "                    # store_count += 1\n",
    "                    # # print(f'\\tstore_freq:{store_freq}, batch:{batch}')\n",
    "                    # if store_count%freq_reduce_after==0:\n",
    "                    #     store_freq += freq_reduce_by\n",
    "                    #     # print(f'store freq:{store_freq}, batch:{batch}')\n",
    "                    grad_norm_per_update = self.get_gradient()\n",
    "                    print('grad:', grad_norm_per_update)\n",
    "                    # print('\\tgrad norm:', grad_norm_per_update)\n",
    "                    self.grads_norms.append(grad_norm_per_update)\n",
    "                    # self.grads_normsv2.append(self.get_gradientv2(X,y))\n",
    "                ## computing and saving hessian\n",
    "                if store_hessian and (batch% store_freq==0):\n",
    "                    #assert False, \"Not implemented\"\n",
    "                    self.optimizer.zero_grad()\n",
    "                    hess_val = self.get_hessianv2(X,y)\n",
    "                    print('hess:',hess_val)\n",
    "                    self.hess_norms.append(hess_val)\n",
    "                    store_count += 1\n",
    "                    if store_count%freq_reduce_after==0:\n",
    "                        store_freq += freq_reduce_by\n",
    "                \n",
    "                ## computing and storing the generalization error\n",
    "                if store_gen_err and (batch% store_freq == 0):\n",
    "                    assert False, \"fix reducing freq to get it working and fastX, fasty\"\n",
    "                    train_loss, test_loss, point_loss=0, 0, 0\n",
    "                    with torch.no_grad():\n",
    "                        for sub_batch, (X_local,y_local) in enumerate(train_loader):\n",
    "                            # if sub_batch> batch: # only taking the encountered points to calculate train loss\n",
    "                            #     break\n",
    "                            X_local, y_local = X_local.to(device), y_local.to(device)\n",
    "                            pred_local = self.model(X_local)\n",
    "                            train_loss += self.loss_fn(pred_local, y_local).item()\n",
    "                    train_loss = train_loss/(batch+1)\n",
    "                    with torch.no_grad():\n",
    "                        for sub_batch, (X_local,y_local) in enumerate(test_loader):\n",
    "                            X_local, y_local = X_local.to(device), y_local.to(device)\n",
    "                            pred_local = self.model(X_local)\n",
    "                            test_loss += self.loss_fn(pred_local, y_local).item()\n",
    "                    test_batch_size = len(test_loader)\n",
    "                    # print(f\"Number of batches in test:{len(test_loader)}\")\n",
    "                    test_loss = test_loss/ len(test_loader)\n",
    "                    self.train_loss.append(train_loss)\n",
    "                    self.val_loss.append(test_loss)\n",
    "                \n",
    "                if batch % 1000 == 0:\n",
    "                    loss, current = loss.item(), batch * len(X)\n",
    "                    correct = 0\n",
    "                    test_loss = 0\n",
    "                    with torch.no_grad():\n",
    "                        for X, y in test_loader:\n",
    "                            X, y = X.to(device), y.to(device)\n",
    "                            pred = self.model(X)\n",
    "                            test_loss += self.loss_fn(pred, y).item()\n",
    "                            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                    acc = 100*correct/len(test_loader.dataset)\n",
    "                    print(f\"\\taccuracy:{acc}\")#, at batch:{batch}\")\n",
    "                    print(f\"\\tloss: {loss:>7f}\")\n",
    "                \n",
    "                    # print(f'Learning rate:{self.scheduler.get_last_lr()}')\n",
    "                self.scheduler.step()\n",
    "            \n",
    "def exp_get_lp_sm(train_data_all, test_data_all, op_features, weight = 10, times = 8, epochs = 1, root_dir='', path=None, clear_file = True, freq_reduce_by=10, freq_reduce_after=100):\n",
    "    grad_list        = []\n",
    "    hess_norm_list   = []\n",
    "    if path is not None:\n",
    "        grad_file_path = root_dir+'grad_'+path\n",
    "        hess_file_path = root_dir+'hess_'+path\n",
    "        # gen_file_path = root_dir+'gen_'+path\n",
    "        if clear_file:\n",
    "            with open(grad_file_path, 'w+') as f:\n",
    "                f.write('')\n",
    "            with open(hess_file_path, 'w+') as f:\n",
    "                f.write('')\n",
    "    \n",
    "    train_loader, test_loader = get_random_subset(train_data_all, test_data_all)\n",
    "    for t in range(times):\n",
    "        print(f'Time:{t}')\n",
    "        train_model = Train_nn(784, weight, op_features, lr= details['alpha_0'], decay=False)\n",
    "        train_model.fit(train_loader, test_loader, epochs=epochs, store_grads=True, store_hessian=True, store_freq=details['book_keep_freq'],  store_gen_err=False, store_pt_loss=False, store_weights=False, freq_reduce_by = freq_reduce_by, freq_reduce_after=freq_reduce_after, )\n",
    "        \n",
    "        with open(grad_file_path,'a+') as f:\n",
    "            f.write(' '.join([str(grad) for grad in train_model.grads_norms]) + '\\n')\n",
    "        with open(hess_file_path,'a+') as f:\n",
    "            f.write(' '.join([str(hess) for hess in train_model.hess_norms]) + '\\n')\n",
    "        \n",
    "        hess_norm_list.append(train_model.hess_norms)\n",
    "        grad_list.append(train_model.grads_norms)\n",
    "         \n",
    "    return grad_list, hess_norm_list\n",
    "\n",
    "grad_list, hess_norm_list = exp_get_lp_sm(train_data_all, test_data_all, op_features=10, \n",
    "              weight=details['g_weight'], times=details['g_times'], \n",
    "              epochs=details['g_epochs'], root_dir=details['result_root_dir'], \n",
    "              path=details['result_path'], freq_reduce_by=details['freq_reduce_by'], \n",
    "              freq_reduce_after=details['freq_reduce_after'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8494ac9-c2b4-4bc4-8c55-8184fb67f913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
