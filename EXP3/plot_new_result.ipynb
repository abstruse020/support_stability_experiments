{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb277049-b700-4107-8ee6-089a11ef000f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Over parameterized network Non decreasing lr result code (not ran exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fe1ba3-4d2f-4131-a53e-40ca1bd0c78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "def get_exp_details(root_dir, path):\n",
    "    result_details={}\n",
    "    details_path = root_dir+ 'details_'+ path + '.txt'\n",
    "    with open(details_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        key, val = line[:-1].split(':')\n",
    "        key, val = key.strip(' '), val.strip(' ')\n",
    "        if key in ['ratio', 'alpha_0']:\n",
    "            val = float(val)\n",
    "        if key in ['Times', 'Weights', 'Epochs', 'book_keep_freq', 'g_times', 'g_epochs', 'freq_reduce_by', 'freq_reduce_after']:\n",
    "            val = int(val)\n",
    "        elif key in ['g_weight']:\n",
    "            print('weight:', val)\n",
    "            val = [int(t) for t in val[1:-1].split(', ')]\n",
    "        result_details[key] = val\n",
    "    return result_details\n",
    "\n",
    "def get_exp_results(r_det, train_size=20000):\n",
    "    root_dir = r_det['result_root_dir']\n",
    "    path = r_det['result_path']\n",
    "    grad_file_path = root_dir+'grad_'+path\n",
    "    hess_file_path = root_dir+'hess_'+path\n",
    "    gen_file_path  = root_dir+'gen_'+path\n",
    "    \n",
    "    # print(result_details)\n",
    "    grad_list    = []\n",
    "    hess_list    = []\n",
    "    gen_err_list = []\n",
    "    \n",
    "    with open(grad_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tensors = line[:-1].split(') ')\n",
    "        # print('tensors',tensors)\n",
    "        t_list = [float(t[7:].split(' ')[0][:-1]) for t in tensors]\n",
    "        # print('grad_list_i length:',len(t_list))\n",
    "        grad_list.append(t_list)\n",
    "    \n",
    "    with open(hess_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tensors = line[:-1].split(' ')\n",
    "        # print('tensors',tensors)\n",
    "        t_list = [float(t[7:-1]) for t in tensors]\n",
    "        # print('hess_list_i length:',len(t_list))\n",
    "        hess_list.append(t_list)\n",
    "    hess_list = np.array(hess_list)\n",
    "    grad_list = np.array(grad_list)\n",
    "    print('hess list shape:',hess_list.shape)\n",
    "    print('grad list shape:',grad_list.shape)\n",
    "    K_g = np.max(np.mean(np.array(grad_list), 0))\n",
    "    L_g = np.max(np.mean(np.array(hess_list), 0))\n",
    "    \n",
    "    book_keep_freq = r_det['book_keep_freq']\n",
    "    freq_reduce_after = r_det['freq_reduce_after']\n",
    "    freq_reduce_by = r_det['freq_reduce_by']\n",
    "    x_values = []\n",
    "    count_keep = 0\n",
    "    for i in range(train_size):\n",
    "        if i%book_keep_freq==0:\n",
    "            x_values.append(i+1)\n",
    "            count_keep+=1\n",
    "            if count_keep%freq_reduce_after==0:\n",
    "                book_keep_freq+=freq_reduce_by\n",
    "    \n",
    "    return grad_list, hess_list, K_g, L_g, x_values\n",
    "\n",
    "def plot_exp_data(root_dir_list, path_list, weights_list, save_fig=False, train_size=20000):\n",
    "    grad_mean_list = []\n",
    "    grad_df_list = []\n",
    "    grad_err_list  = []\n",
    "    hess_mean_list = []\n",
    "    hess_df_list = []\n",
    "    hess_err_list  = []\n",
    "    data = {}\n",
    "    x_values = []\n",
    "    for root_dir, path, weights in zip(root_dir_list, path_list, weights_list):\n",
    "        print('for weight:', weights)\n",
    "        res_details = get_exp_details(root_dir, path)\n",
    "        grad_list, hess_list, K_g, L_g, x_values = get_exp_results(res_details, train_size)\n",
    "        grad_list_m = np.max(grad_list,1)\n",
    "        hess_list_m = np.max(hess_list,1)\n",
    "        # K_g = np.percentile(np.mean(grad_list, 0),90)\n",
    "        # L_g = np.percentile(np.mean(hess_list, 0),90)\n",
    "        \n",
    "        # K_g = np.max(np.mean(grad_list, 1))\n",
    "        # L_g = np.max(np.mean(hess_list, 1))\n",
    "        # print('grad_list shape',grad_list_m.shape)\n",
    "        # print('grad_list ',grad_list_m)\n",
    "        # print(f'K_g:{K_g}, L_g:{L_g}')\n",
    "        grad_mean, grad_err = np.mean(grad_list_m), np.std(grad_list_m)\n",
    "        hess_mean, hess_err = np.mean(hess_list_m), np.std(hess_list_m)\n",
    "        grad_mean_list.append(grad_mean)\n",
    "        grad_err_list.append(grad_err)\n",
    "        hess_mean_list.append(hess_mean)\n",
    "        hess_err_list.append(hess_err)\n",
    "        params_size = 784\n",
    "        for weight in weights:\n",
    "            params_size*= weight\n",
    "        x_values.append(str(params_size))\n",
    "        for run_id in range(len(grad_list)):\n",
    "            for epoch in range(len(grad_list[run_id])):\n",
    "                grad_df_list.append({'key':int(params_size), 'run_id': run_id, 'epoch':epoch, 'val': grad_list[run_id][epoch]})\n",
    "                                      \n",
    "        for run_id in range(len(hess_list)):\n",
    "            for epoch in range(len(hess_list[run_id])):\n",
    "                hess_df_list.append({'key':int(params_size), 'run_id': run_id, 'epoch':epoch, 'val': hess_list[run_id][epoch]})\n",
    "        \n",
    "        # plt.errorbar(x_values, np.mean(grad_list,0),np.std(grad_list,0), label='ratio:'+str(ratio))\n",
    "    df1 = pd.DataFrame(grad_df_list)\n",
    "    df2 = pd.DataFrame(hess_df_list)\n",
    "    \n",
    "    temp_df1 = df1.groupby(['key','run_id'])['val'].max().reset_index()\n",
    "    temp_df2 = df2.groupby(['key','run_id'])['val'].max().reset_index()\n",
    "    # temp_df1 = df1\n",
    "    # temp_df2 = df2\n",
    "    grad_mean_list = np.array(grad_mean_list)\n",
    "    grad_err_list = np.array(grad_err_list)\n",
    "    hess_mean_list = np.array(hess_mean_list)\n",
    "    hess_err_list = np.array(hess_err_list)\n",
    "    # x_values = [str(int(train_size*t)) for t in ratios]\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    sns.pointplot(data = temp_df1, x='key',y='val', estimator=np.mean, ax=ax, label='Lipschitz const.', color='orange', errwidth=0)\n",
    "    ax.fill_between(x_values, grad_mean_list-grad_err_list, grad_mean_list+ grad_err_list, color='orange', alpha=.3)\n",
    "    plt.xlabel('Number of parameters', fontsize = 24)\n",
    "    plt.ylabel('Lipschitz constant', fontsize = 24)    \n",
    "    sns.set_context(\"talk\")\n",
    "    sns.set(font='sans-serif', style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 2, \"lines.markersize\":10})\n",
    "    plt.title('Mnist dataset', fontsize=24)\n",
    "    if save_fig:\n",
    "        plt.savefig('e3_Lipschitz_constant_mnist.png')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    sns.pointplot(data = temp_df2, x='key',y='val', ax=ax, label='Smoothness const.', color='green', errwidth=0)\n",
    "    ax.fill_between(x_values, hess_mean_list-hess_err_list, hess_mean_list+ hess_err_list, color='green', alpha=.3)\n",
    "    plt.xlabel('Number of parameters', fontsize = 24)\n",
    "    plt.ylabel('Smoothness constant', fontsize = 24)    \n",
    "    sns.set_context(\"talk\")\n",
    "    sns.set(font='sans-serif', style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 2, \"lines.markersize\":10})\n",
    "    # plt.show()\n",
    "    plt.title('Mnist dataset', fontsize=24)\n",
    "    if save_fig:\n",
    "        plt.savefig('e3_Smoothness_constant_mnist.png')\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a0c903-2461-4770-861a-42f59b041bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for weight: [12]\n",
      "weight: [12]\n",
      "hess list shape: (0,)\n",
      "grad list shape: (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/harsh/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m ratios\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m4.\u001b[39m, \u001b[38;5;241m6.\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m weights_list \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m12\u001b[39m], [\u001b[38;5;241m16\u001b[39m], [\u001b[38;5;241m25\u001b[39m]]\n\u001b[0;32m----> 5\u001b[0m grad_df, hess_f\u001b[38;5;241m=\u001b[39m \u001b[43mplot_exp_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_fig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mplot_exp_data\u001b[0;34m(root_dir_list, path_list, weights_list, save_fig, train_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m res_details \u001b[38;5;241m=\u001b[39m get_exp_details(root_dir, path)\n\u001b[1;32m     85\u001b[0m grad_list, hess_list, K_g, L_g, x_values \u001b[38;5;241m=\u001b[39m get_exp_results(res_details, train_size)\n\u001b[0;32m---> 86\u001b[0m grad_list_m \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_list\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m hess_list_m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(hess_list,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# K_g = np.percentile(np.mean(grad_list, 0),90)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# L_g = np.percentile(np.mean(hess_list, 0),90)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# print('grad_list ',grad_list_m)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# print(f'K_g:{K_g}, L_g:{L_g}')\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2754\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2640\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2641\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2642\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2643\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2755\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "root_dir_list = ['results/t0/','results/t0/','results/t0/']\n",
    "path_list = ['try1_t8_w12', 'try1_t8_w16', 'try1_t8_w25']\n",
    "ratios= [4., 6., 10.0, 1]\n",
    "weights_list = [[12], [16], [25]]\n",
    "grad_df, hess_f= plot_exp_data(root_dir_list[:], path_list[:], weights_list[:], save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960550d-5c86-42bc-b8fa-e194f6d20ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
