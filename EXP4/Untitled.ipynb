{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9415a4f8-a7ac-447a-9310-3612a5ae35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd.functional import hessian\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdcc74ee-5326-42fe-b2c8-76b83a902520",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9303fee7-8129-4c59-91e0-02d756842166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d451be4-9035-4169-b0d0-7b852ce2a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "\n",
    "## Have to use this flag while running above\n",
    "# CUBLAS_WORKSPACE_CONFIG=:16:8 or CUBLAS_WORKSPACE_CONFIG=:4096:2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094c67bd-8705-44da-96ad-adeeb094253b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:20000\n",
      "test data size:1000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\"\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "# print(f'train data:{train_data}')\n",
    "# print(f'test data:{test_data}')\n",
    "train_indices = torch.arange(20000)\n",
    "test_indices = torch.arange(1000)\n",
    "train_data = data_utils.Subset(train_data, train_indices)\n",
    "test_data = data_utils.Subset(test_data, test_indices)\n",
    "# print(f'train data:{train_data}')\n",
    "# print(f'test data:{test_data}')\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=256,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")\n",
    "print(f'train data size:{len(train_loader.dataset)}')\n",
    "print(f'test data size:{len(test_loader.dataset)}')\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, hidden_layers, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = len(hidden_layers) + 1\n",
    "        self.total_params_len = 0\n",
    "        self.fc1 = nn.Linear(input_features, hidden_layers[0])\n",
    "        self.total_params_len += input_features*hidden_layers[0] + hidden_layers[0]\n",
    "        self.fc2 = nn.Linear(hidden_layers[0], output_size)\n",
    "        self.total_params_len += hidden_layers[0]*output_size + output_size\n",
    "        \n",
    "        ### Others required params\n",
    "        self.param_list = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        # print('x shape in forward',x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x     \n",
    "\n",
    "class Train_nn:\n",
    "    \n",
    "    def __init__(self, input_features, hidden_layers, output_size, lr):\n",
    "        self.model = Net(input_features, hidden_layers=hidden_layers, output_size=output_size)\n",
    "        self.model.to(device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        \n",
    "    def get_loss(self, X, y, params=None):\n",
    "        # if params is not None:\n",
    "        assert False, \"Model not initialized with given params\"\n",
    "        op = self.model(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        return loss\n",
    "    \n",
    "    def get_gradient(self):\n",
    "        params = (self.model.parameters())\n",
    "        grad_norm_sq = torch.tensor(0, dtype=float).to(device)\n",
    "        # print('grad Norm init:', grad_norm_sq)\n",
    "        for param in self.model.parameters():\n",
    "            temp = param.grad.data.pow(2).sum()\n",
    "            # print(f'param grad norm \\n\\tsum:{temp.data}')#,\\n\\tshape:{param.shape}')\n",
    "            grad_norm_sq += temp\n",
    "            \n",
    "        return grad_norm_sq.sqrt().cpu()\n",
    "    \n",
    "    def try_operator_norm(self, hess_mat):\n",
    "        for i in len(hess_mat):\n",
    "            for j in len(hess_mat[0]):\n",
    "                torch.unsqueeze(hess_mat[i][i],0)\n",
    "        hess_tensor_dim = list(hess_mat[0][0].shape)\n",
    "        hess_tensor_dim += [n*2,n*2]\n",
    "        hess_mat_np = np.zeros(shape=hess_tensor_dim)\n",
    "        hess_tensor = torch.tensor(hess_mat_np)\n",
    "        torch.cat(hess_mat, out=hess_tensor)\n",
    "        \n",
    "        hess_mat.reshpe(n*2,n*2)\n",
    "        hess_norm = torch.linalg.norm(hess_mat, 2)\n",
    "        assert False, \"Not working\"\n",
    "    \n",
    "    def get_hessian(self, X, y):\n",
    "        prev_params = copy.deepcopy(list(self.model.parameters()))\n",
    "        n = self.model.layers\n",
    "        def local_model(*params):\n",
    "            # print(f'len of params:{len(params)}')\n",
    "            # print(f'shape of params[0]:{params[0].shape}')\n",
    "            # with torch.no_grad():\n",
    "            #initialize model with given params\n",
    "            i = 0\n",
    "            for i, param in enumerate(self.model.parameters()):\n",
    "                param.data = params[i]\n",
    "            pred = self.model(X)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "            # print(f'loss type:{type(loss)}')\n",
    "            return loss\n",
    "        p =list(self.model.parameters())\n",
    "        hess_mat = hessian(local_model, tuple(p))\n",
    "        hess_norm = torch.tensor(0.).to(device)\n",
    "        for i in range(len(hess_mat)):\n",
    "            for j in range(len(hess_mat[0])):\n",
    "                hess_norm+= hess_mat[i][j].pow(2).sum()\n",
    "        \n",
    "        # print(f'Hess mat len:{len(hess_mat)}')\n",
    "        # print(f'Hess mat[0] len:{len(hess_mat[0])}')\n",
    "        # print(f'Hess mat[0][0] shape:{hess_mat[0][0].shape}')\n",
    "        \n",
    "        hess_norm = hess_norm.sqrt()\n",
    "        print(f'hess norm:{hess_norm}')\n",
    "        \n",
    "        # Reinitialize the original params to model\n",
    "        for i, param in enumerate(self.model.parameters()):\n",
    "                param.data = prev_params[i]\n",
    "        \n",
    "        return hess_norm\n",
    "        \n",
    "    def fit(self, train_loader, test_loader, epochs, store_grads=False, store_hessian=False, store_gen_err=False, store_weights=False, store_pt_loss=True, store_freq = 10, decrease_freq_after = None):\n",
    "        \n",
    "        ## For Book keeping results ##\n",
    "        self.grads_norms = []\n",
    "        self.param_list = []\n",
    "        self.hess_norms = []\n",
    "        self.gen_err = []\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.point_loss = []\n",
    "        ## Initializing values ##\n",
    "        terminate_training = False\n",
    "        \n",
    "        for epoch in tqdm(range(epochs), total=epochs, unit=\"epoch\", disable=True):\n",
    "            if terminate_training == True:\n",
    "                break\n",
    "            for batch, (X, y) in tqdm(enumerate(train_loader), total=len(train_loader), unit='batch'):\n",
    "                if batch>300:\n",
    "                    terminate_training = True\n",
    "                    break\n",
    "                X, y =X.to(device), y.to(device)\n",
    "                pred = self.model(X)\n",
    "                loss = self.loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                ## Saving point loss\n",
    "                if store_pt_loss and (batch%store_freq==0):\n",
    "                    self.point_loss.append(loss.item())\n",
    "                    \n",
    "                ## Saving the weights\n",
    "                if store_weights and (batch%store_freq==0):\n",
    "                    current_params = tuple(self.model.parameters())\n",
    "                    self.param_list.append(current_params)\n",
    "                \n",
    "                ## computing and saving the gradient\n",
    "                if store_grads and (batch% store_freq == 0):\n",
    "                    # print('Batch:', batch)\n",
    "                    grad_norm_per_update = self.get_gradient()\n",
    "                    # print('\\tgrad norm:', grad_norm_per_update)\n",
    "                    self.grads_norms.append(grad_norm_per_update)\n",
    "                    \n",
    "                ## computing and saving hessian\n",
    "                if store_hessian and (batch% store_freq==0):\n",
    "                    #assert False, \"Not implemented\"\n",
    "                    self.optimizer.zero_grad()\n",
    "                    self.hess_norms.append(self.get_hessian(X,y))\n",
    "                    \n",
    "                \n",
    "                ## computing and storing the generalization error\n",
    "                if store_gen_err and (batch% store_freq == 0):\n",
    "                    train_loss, test_loss, point_loss=0, 0, 0\n",
    "                    with torch.no_grad():\n",
    "                        for sub_batch, (X_local,y_local) in enumerate(train_loader):\n",
    "                            if sub_batch> batch: # only taking the encountered points to calculate train loss\n",
    "                                break\n",
    "                            X_local, y_local = X_local.to(device), y_local.to(device)\n",
    "                            pred_local = self.model(X_local)\n",
    "                            train_loss += self.loss_fn(pred_local, y_local).item()\n",
    "                    train_loss = train_loss/(batch+1)\n",
    "                    with torch.no_grad():\n",
    "                        for sub_batch, (X_local,y_local) in enumerate(test_loader):\n",
    "                            X_local, y_local = X_local.to(device), y_local.to(device)\n",
    "                            pred_local = self.model(X_local)\n",
    "                            test_loss += self.loss_fn(pred_local, y_local).item()\n",
    "                    test_batch_size = len(test_loader)\n",
    "                    # print(f\"Number of batches in test:{len(test_loader)}\")\n",
    "                    test_loss = test_loss/ len(test_loader)\n",
    "                    self.train_loss.append(train_loss)\n",
    "                    self.val_loss.append(test_loss)\n",
    "                \n",
    "                if batch % 100 == 0:\n",
    "                    loss, current = loss.item(), batch * len(X)\n",
    "                    correct = 0\n",
    "                    test_loss = 0\n",
    "                    with torch.no_grad():\n",
    "                        for X, y in test_loader:\n",
    "                            X, y = X.to(device), y.to(device)\n",
    "                            pred = self.model(X)\n",
    "                            test_loss += self.loss_fn(pred, y).item()\n",
    "                            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                    acc = 100*correct/len(test_loader.dataset)\n",
    "                    print(f\"\\taccuracy:{acc}\")#, at batch:{batch}\")\n",
    "                    print(f\"\\tloss: {loss:>7f}\")\n",
    "            \n",
    "\n",
    "# net = Net(input_features=784, hidden_sizes = [16], output_size = 10)\n",
    "# print(net)\n",
    "# params = list(net.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(net.parameters())\n",
    "train_nn = Train_nn(784, [16], 10,lr= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d8966fe-1430-4733-a100-bdc1a6747782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import _stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebaada4-61d2-40da-adb1-9140b5537587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8037c264f384545aa0f56911e5a9b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taccuracy:9.1\n",
      "\tloss: 2.209228\n",
      "\taccuracy:10.8\n",
      "\tloss: 2.361486\n",
      "\taccuracy:13.7\n",
      "\tloss: 2.172824\n",
      "\taccuracy:17.1\n",
      "\tloss: 2.320117\n"
     ]
    }
   ],
   "source": [
    "train_nn.fit(train_loader, test_loader, epochs=1, store_grads=True,store_hessian=False, store_freq=10, store_gen_err=True, store_pt_loss=True, store_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448cf29e-46bc-4996-bc8e-324e71d10ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_nn.grads_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a48d886-fe02-4d0e-a287-68a7f52cb39b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(train_nn.grads_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8108be2a-14b8-4cfb-bcf6-0975c7f6fb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3e9938f730>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(train_nn.train_loss) - np.array(train_nn.val_loss))\n",
    "plt.plot(train_nn.point_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5ed1ccd1-cc90-4c6a-ad6e-6c4b0521f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = iter(train_loader).next()\n",
    "X, y = X.to(device), y.to(device)\n",
    "def local_model(*params):\n",
    "    # print(f'len of params:{len(params)}')\n",
    "    # print(f'shape of params[0]:{params[0].shape}')\n",
    "    with torch.no_grad():\n",
    "        #initialize model with given params\n",
    "        i = 0\n",
    "        var = torch.tensor(1.).to(device)\n",
    "        print(params[1].shape)\n",
    "        for param in train_nn.model.parameters():\n",
    "            param.data = torch.zeros(params[i].shape[0], params[i].shape[1])\n",
    "            i += 1\n",
    "        pred = train_nn.model(X)\n",
    "        loss = train_nn.loss_fn(pred, y)\n",
    "        # print(f'loss type:{type(loss)}')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ff80b823-69f9-41c5-a440-06c2faf392a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [216]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hess_mat \u001b[38;5;241m=\u001b[39m \u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:808\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[1;32m    805\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[0;32m--> 808\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:575\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    572\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    573\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 575\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:804\u001b[0m, in \u001b[0;36mhessian.<locals>.jac_func\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_jacobian_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-mode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;66;03m# _grad_preprocess requires create_graph=True and input to require_grad\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# or else the input will be detached\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inp)\n\u001b[0;32m--> 804\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_single_output_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:575\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    572\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    573\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 575\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/functional.py:787\u001b[0m, in \u001b[0;36mhessian.<locals>.ensure_single_output_function\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_single_output_function\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m--> 787\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     is_out_tuple, t_out \u001b[38;5;241m=\u001b[39m _as_tuple(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhessian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    789\u001b[0m     _check_requires_grad(t_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "Input \u001b[0;32mIn [215]\u001b[0m, in \u001b[0;36mlocal_model\u001b[0;34m(*params)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(params[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m train_nn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m---> 12\u001b[0m     param\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, params[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     13\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m pred \u001b[38;5;241m=\u001b[39m train_nn\u001b[38;5;241m.\u001b[39mmodel(X)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "hess_mat = hessian(local_model, tuple(list(train_nn.model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258aaa86-57bb-4744-96f6-778d6d33f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_mat[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45491ab3-f6c0-4def-8258-db6b57dce410",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(train_nn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mlist\u001b[39m(train_nn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'generator' object"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    params = copy.deepcopy(train_nn.model.parameters())\n",
    "    print(list(train_nn.model.parameters())[0][0][0])\n",
    "    list(train_nn.model.parameters())[0][0][0]=2\n",
    "    print(list(train_nn.model.parameters())[0][0][0])\n",
    "    print(params[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "118fea56-4357-4cd7-ad03-a454d59d69f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fb67c-e72d-4b84-a041-b06d360ba22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ad60e-85c9-4b32-a7ca-7255fe29058f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10cdf26e-e1c4-4f61-aff8-6bb2db99be94",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a view of a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a view of a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "params[0][0][0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "504deb6b-b56f-4c5b-b07b-aa91ce8589a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn.model.state_dict()['fc1.weight'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22b4dfd7-1b8a-41a4-9653-c43dd8772ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val = torch.tensor(2.).to(device)\n",
    "for param in train_nn.model.parameters():\n",
    "    param.data[0][0] = new_val\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f8960c-110e-4772-ba9b-62176b496335",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_changed = list(train_nn.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f054236-09c9-4690-8c27-e099589a867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_changed[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45192dcb-5965-4244-b3c2-49aeb6cc9d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "153460aa-fc80-4397-b14d-fe5d8da2f58b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(5)\n",
    "for i, (data, label) in enumerate(train_loader):\n",
    "    if i>= 5:\n",
    "        break\n",
    "    ax[i].imshow(data.reshape(28,28))\n",
    "\n",
    "iter(train_loader).next()[0].reshape(28,28)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa8e587e-6325-4f62-acc3-fc4b3d17fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f7c1d06-c21a-4c11-be9a-1a46da6b309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out torch.Size([5, 10])\n",
      "tensor([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "model_ip = torch.ones(5,784)\n",
    "out = net(model_ip)\n",
    "print('out', out.shape)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "target = torch.ones(5, dtype = torch.long)\n",
    "print(target)\n",
    "loss = criterion(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb6d7827-2a3f-45cc-bbb2-cc5dd2807d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3769, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c860f569-81bb-45ef-b60f-05b3b1bc1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(2,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc1ad8-6d39-48f9-9232-608dc73c64b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cb52f81-f157-45cb-82fa-a9ce0a3f4e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# print(param)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    # print(param)\n",
    "    print(param.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985eb3c3-88ae-4cfe-8c7f-748004e723c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861f399-656c-47fe-88ed-6b5a22f61517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1b35062-bdbb-4f38-af25-134b6527da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[0]**2 + 4*x[1]**3 -10*x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61ecf17d-b92f-44d6-8ad8-0181c567833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2d(x):\n",
    "    return x[0][0]**2 + 4*x[0][1]**3 -10*x[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1acfdcd0-2624-44cf-a2c5-226ebec2d257",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [2., 1.]])\n",
      "tensor([1., 1., 2., 1.])\n",
      "1d\n",
      "tensor([[ 2.,  0.,  0.,  0.],\n",
      "        [ 0., 24.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.]])\n",
      "2d\n",
      "tensor([[[[ 2.,  0.],\n",
      "          [ 0.,  0.]],\n",
      "\n",
      "         [[ 0., 24.],\n",
      "          [ 0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.],\n",
      "          [ 0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.],\n",
      "          [ 0.,  0.]]]])\n",
      "tensor([[ 2.,  0.,  0.,  0.],\n",
      "        [ 0., 24.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "ip2d = torch.tensor([[1.,1.],[2.,1.]]) \n",
    "print(ip2d)\n",
    "ip1d = torch.flatten(ip2d)\n",
    "print(ip1d)\n",
    "\n",
    "print('1d')\n",
    "print(hessian(func, ip1d))\n",
    "print('2d')\n",
    "hess_2d = hessian(func2d, ip2d)\n",
    "print(hess_2d)\n",
    "print(torch.reshape(hess_2d, (4,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e7f65dad-d64c-4deb-a2d8-c42ee1495262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_const(*x):\n",
    "    return torch.tensor(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "424f0ce5-f35c-4c22-8593-7603fcfb7791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "p =list(train_nn.model.parameters())\n",
    "print(type(tuple(p)))\n",
    "p_hes = hessian(func_const, tuple(p))\n",
    "print(len(p_hes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd6b04fe-fb2f-4101-b1c8-90e35ed65d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 784, 16, 784])\n"
     ]
    }
   ],
   "source": [
    "print(p_hes[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064da51-94d3-4e1b-b1e6-ee65e4148802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e5374d96-ab1e-4586-9ea2-277b679abcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_hes_t shape:torch.Size([16, 16, 784, 16, 784])\n"
     ]
    }
   ],
   "source": [
    "base_h_dim = list(p_hes[0][0].shape)\n",
    "base_h_dim = [4*4] + base_h_dim\n",
    "p_hes_t = np.zeros(base_h_dim)\n",
    "p_hes_t = torch.tensor(p_hes_t)\n",
    "print(f'p_hes_t shape:{p_hes_t.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "244d9df7-9344-49fc-9d41-69e1c889260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hes_list = [0]*4*4\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        p_hes_list[i*4 + j] = torch.unsqueeze(p_hes[i][j],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c89d52e2-1306-4392-a6bf-c1efb906d639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 784, 16, 784])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hes_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0ec57925-eafa-427e-9390-7d419db193ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 5 and 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [169]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp_hes_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_hes_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 5 and 4"
     ]
    }
   ],
   "source": [
    "torch.cat(tuple(p_hes_list), out=p_hes_t.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84677bb4-5ef9-4745-aeb9-c9f110383b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1175b077-edc1-40df-bd54-3f84299e9118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 784, 16, 784])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hes[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f505fb5-9ef7-471c-873c-98075be69128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 2., 1.])\n",
      "1d\n",
      "tensor([[ 2.,  0.,  0.,  0.],\n",
      "        [ 0., 24.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "ip1d = torch.flatten(ip2d)\n",
    "print(ip1d)\n",
    "\n",
    "print('1d')\n",
    "print(hessian(func, ip1d))\n",
    "print(hessian(func_const, ip1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a0b02a2-14cb-4cef-b41b-72960e82b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testnet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, hidden_sizes, output_size):\n",
    "        super(Testnet, self).__init__()\n",
    "        self.total_params_len = 0\n",
    "        self.fc1 = nn.Linear(input_features, hidden_sizes[0])\n",
    "        self.total_params_len += input_features*hidden_sizes[0] + hidden_sizes[0]\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], output_size)\n",
    "        self.total_params_len += hidden_sizes[0]*output_size + output_size\n",
    "        \n",
    "        ### Others required params\n",
    "        self.param_list = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "test_net = Testnet(2,[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae510dd7-10bf-4bd7-8f21-2708357f00bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1769, -0.0553]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2762], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.6002]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2901], requires_grad=True)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fb500-ea65-487e-919a-c3830aa7ee41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
