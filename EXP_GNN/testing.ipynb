{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import degree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_dataset = Planetoid(root='.', name='Cora')\n",
    "cora_data = cora_dataset[0].to(device)\n",
    "cora_data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "cora_loader = DataLoader(cora_dataset, batch_size=16, shuffle=True)\n",
    "for batch in cora_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6], device='cuda:2')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cora_data.train_mask\n",
    "cora_data.y.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:\n",
      " tensor([[0.2521, 0.9817, 0.0370],\n",
      "        [0.0510, 0.4707, 0.3776],\n",
      "        [0.1217, 0.2523, 0.0912],\n",
      "        [0.0775, 0.5659, 0.9049],\n",
      "        [0.2312, 0.4914, 0.9360]], dtype=torch.float64)\n",
      "edges:\n",
      " tensor([[0., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making Dummy data\n",
    "\n",
    "features = torch.rand(5,3, dtype=float) # 5 nodes, 3 features\n",
    "edges = torch.randint_like(torch.zeros(2,4), 2)\n",
    "\n",
    "## Making graph un directed\n",
    "edges = torch.cat([edges, torch.stack([ edges[1], edges[0]], dim = 0)], dim = 1)\n",
    "\n",
    "print('features:\\n', features)\n",
    "print('edges:\\n', edges)\n",
    "\n",
    "graph_data = Data(x=features, edge_index=edges)\n",
    "\n",
    "graph_data.is_directed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, num_class = 2):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_features, 50)\n",
    "        self.conv2 = GCNConv(50, num_class)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        self.conv1(x, edge_index)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9488041400909424\n",
      "1.7172476053237915\n",
      "1.4754453897476196\n",
      "1.2062066793441772\n",
      "0.957212507724762\n",
      "0.7603483200073242\n",
      "0.5763006210327148\n",
      "0.4430246651172638\n",
      "0.34446558356285095\n",
      "0.23802506923675537\n",
      "0.19557404518127441\n",
      "0.14379356801509857\n",
      "0.10606261342763901\n",
      "0.08529900759458542\n",
      "0.07111141085624695\n",
      "0.05544662848114967\n",
      "0.04522155970335007\n",
      "0.028784608468413353\n",
      "0.04151010140776634\n",
      "0.02557826228439808\n",
      "0.02306334301829338\n",
      "0.03018876537680626\n",
      "0.02635553665459156\n",
      "0.016293328255414963\n",
      "0.013776899315416813\n",
      "0.012089678086340427\n",
      "0.010503326542675495\n",
      "0.012259312905371189\n",
      "0.012226182036101818\n",
      "0.007974456064403057\n",
      "0.01450271811336279\n",
      "0.008107977919280529\n",
      "0.006945633329451084\n",
      "0.005296339746564627\n",
      "0.007954574190080166\n",
      "0.010217642411589622\n",
      "0.010253830812871456\n",
      "0.005610763560980558\n",
      "0.009604820981621742\n",
      "0.010569410398602486\n",
      "0.007973745465278625\n",
      "0.007452824153006077\n",
      "0.011830199509859085\n",
      "0.008153163827955723\n",
      "0.011647247709333897\n",
      "0.011631709523499012\n",
      "0.008580955676734447\n",
      "0.011507805436849594\n",
      "0.010221350006759167\n",
      "0.008884277194738388\n"
     ]
    }
   ],
   "source": [
    "## temp training loop\n",
    "epochs = 50\n",
    "num_class = 7\n",
    "num_features = cora_data.num_features\n",
    "model = GCN(num_features,num_class ).to(device)\n",
    "# model = GCN(3).to(device)\n",
    "model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "def train_once(model, optimizer, data):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test_once(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct)/ int(data.test_mask.sum())\n",
    "    return acc\n",
    "\n",
    "\n",
    "epoch_loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(cora_data)\n",
    "    # loss = F.nll_loss(out, cora_data.y)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Our Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_x(x):\n",
    "\n",
    "    vectors_along_one = torch.matmul(x.T, torch.ones(x.shape[0]).type(torch.LongTensor)) * torch.ones(x.shape[0]).unsqueeze_(dim=1)\n",
    "    x_pp = x - vectors_along_one\n",
    "\n",
    "    return x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 1, 0],\n",
      "        [1, 9, 2]])\n",
      "tensor([[3.5000, 5.0000, 1.0000],\n",
      "        [3.5000, 5.0000, 1.0000]])\n",
      "tensor([[ 2.5000, -4.0000, -1.0000],\n",
      "        [-2.5000,  4.0000,  1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-4.7684e-07, -9.5367e-07, -2.3842e-07])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(10, (2,3))\n",
    "print(x)\n",
    "\n",
    "vectors_along_one = torch.matmul(x.T, torch.ones(x.shape[0]).type(torch.LongTensor)) * torch.ones(x.shape[0]).unsqueeze_(dim=1)\n",
    "vectors_along_one /= torch.norm(torch.ones(x.shape[0]))**2\n",
    "print(vectors_along_one)\n",
    "\n",
    "x_new = x - vectors_along_one\n",
    "print(x_new)\n",
    "\n",
    "torch.matmul(x_new.T, torch.ones(x_new.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000) tensor(-0.5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 2.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.tensor([1.,2.])\n",
    "v2 = torch.tensor([1.,1.])\n",
    "v3 = torch.tensor([1.,-1.])\n",
    "\n",
    "alpha1 = torch.dot(v1,v2)/torch.norm(v2)**2\n",
    "alpha2 = torch.dot(v1,v3)/torch.norm(v3)**2\n",
    "\n",
    "print(alpha1, alpha2)\n",
    "\n",
    "alpha1 * torch.tensor([1.,1.]) + alpha2 * torch.tensor([1.,-1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting edges from graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_dataset = Planetoid(root='.', name='Cora')\n",
    "cora_data = cora_dataset[0]\n",
    "cora_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4., 6.,  ..., 2., 5., 5.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree(cora_data.edge_index[0]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total nodes torch.Size([2708])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 5.,  ..., 1., 4., 4.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_deg =torch.zeros(cora_data.num_nodes)\n",
    "print('total nodes', node_deg.shape)\n",
    "\n",
    "\n",
    "for ni,nj in cora_data.edge_index.T:\n",
    "    # print(ni, nj)\n",
    "    node_deg[nj] +=1\n",
    "\n",
    "node_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.1581e-06, -2.3645e-05, -3.1546e-05,  ..., -8.8847e-06,\n",
       "         1.0053e-04, -5.3493e-07])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_x_with_deg(x, edge_index):\n",
    "    vec_deg = degree(edge_index[0]) + 1\n",
    "    vec_deg = torch.sqrt(vec_deg) # vec_deg[i] = sqrt(d_i + 1)\n",
    "    vectors_along_deg = torch.matmul(x.T, vec_deg) * vec_deg.unsqueeze_(dim=1)\n",
    "    vectors_along_deg /= torch.norm(vec_deg)**2\n",
    "    x_pp = x - vectors_along_deg\n",
    "\n",
    "    return x_pp\n",
    "\n",
    "x_perp = preprocess_x_with_deg(cora_data.x, cora_data.edge_index)\n",
    "\n",
    "torch.matmul(x_perp.T, torch.sqrt(degree(cora_data.edge_index[0]) + 1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "- [GCN takes all data features, it just hides labels of test nodes] Make dataloader for batched operation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from utils import get_config, config_to_dict\n",
    "\n",
    "config = get_config(config_path='temp.yaml')\n",
    "# config = get_config()\n",
    "\n",
    "config_dict = config_to_dict(config)\n",
    "\n",
    "\n",
    "with open('temp.yaml', '+w') as f:\n",
    "    yaml.dump(config_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_name': 'exp_cora_vec_deg_v1',\n",
       " 'description': 'Experiment for GCN training on cora dataset, removeing vectors of degrees i.e. sqrt(d_i + 1)',\n",
       " 'epochs': 100,\n",
       " 'batch_size': 16,\n",
       " 'optimizer': namespace(name='adam', lr=0.01, wt_decay=0.0005),\n",
       " 'data': namespace(name='planetoid', num_class=7, num_features=1433),\n",
       " 'result_file': 'result.csv',\n",
       " 'seed': 1234}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m json\u001b[39m.\u001b[39;49mloads(config\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m, object_hook\u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m)\n",
      "File \u001b[0;32m~/stability_exp/EXP_GNN/gnn_env_2/lib/python3.10/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(s, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json.loads(config.__dict__, object_hook= lambda x: x.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
